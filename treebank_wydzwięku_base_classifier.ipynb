{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "treebank_wydzwięku_base_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92e932741b244f0cb813eb976c9a8500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_723d14334454472f8697d32944e830e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bef6dd8abca49208241b19ad5e859fb",
              "IPY_MODEL_c50d7b2a8a844e1a82a70215c0828f45"
            ]
          }
        },
        "723d14334454472f8697d32944e830e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bef6dd8abca49208241b19ad5e859fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b9c3df12d194fc794bd9ab2ceaed200",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 494801,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 494801,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73b2aaf31e0e490baf0b79a808ae1e5b"
          }
        },
        "c50d7b2a8a844e1a82a70215c0828f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bff0a1037b243b28ab08dd04ac8b22c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 495k/495k [00:00&lt;00:00, 1.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5e5df874608482888e2f5ebb0650725"
          }
        },
        "5b9c3df12d194fc794bd9ab2ceaed200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73b2aaf31e0e490baf0b79a808ae1e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bff0a1037b243b28ab08dd04ac8b22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5e5df874608482888e2f5ebb0650725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "753c5785b7f6434db7f042c8a0300e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_687730fe7f7441a0a4ec65ff5c7411b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e4e0d3b47564a0abf822029624aaee5",
              "IPY_MODEL_af0cc2f8864b4d9a96c0f6d92d69bbc7"
            ]
          }
        },
        "687730fe7f7441a0a4ec65ff5c7411b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e4e0d3b47564a0abf822029624aaee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c38f533eec54f598cfaa0f66b3a9fc1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d75519bfae346788fcfefd75c81185a"
          }
        },
        "af0cc2f8864b4d9a96c0f6d92d69bbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2575951bab84d959772753e445789e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 512B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af212f10dfd6465588cfe9eba87a8c52"
          }
        },
        "1c38f533eec54f598cfaa0f66b3a9fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d75519bfae346788fcfefd75c81185a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2575951bab84d959772753e445789e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af212f10dfd6465588cfe9eba87a8c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b805013d1614fa7be3050e87446bf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48de3ea7e6aa4fe1917aab20be9d5ad5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2675a037becc4cab932b1aed347d1a44",
              "IPY_MODEL_8e75207a9c2d498487b5c4a124bff036"
            ]
          }
        },
        "48de3ea7e6aa4fe1917aab20be9d5ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2675a037becc4cab932b1aed347d1a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfb70593b23448b3a21c610b8a991c0d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56c8f1871b8449e0977c046b8fd190ab"
          }
        },
        "8e75207a9c2d498487b5c4a124bff036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25b76bfc00c74b7cb73ac76af6516010",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 20.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0e04cf8be9648219b3e03e1453ac946"
          }
        },
        "bfb70593b23448b3a21c610b8a991c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56c8f1871b8449e0977c046b8fd190ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25b76bfc00c74b7cb73ac76af6516010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0e04cf8be9648219b3e03e1453ac946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bb2ac401411408981cbb866947017b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ecb349e65bf4a9f8c181fb7a6cae589",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9850f8abe62a4cc198350687b185d4d4",
              "IPY_MODEL_b9b1e59a612943f8b12a2510a416e4dc"
            ]
          }
        },
        "5ecb349e65bf4a9f8c181fb7a6cae589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9850f8abe62a4cc198350687b185d4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12cd14a17b854c41a648fa5d8615d13c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1ea0b0cf8d14d45a800761b474ecde5"
          }
        },
        "b9b1e59a612943f8b12a2510a416e4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a21ba56bc8654148bf665a897e9b2f01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 459/459 [00:00&lt;00:00, 634B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_766512519550463ebea2da95c5979c60"
          }
        },
        "12cd14a17b854c41a648fa5d8615d13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1ea0b0cf8d14d45a800761b474ecde5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a21ba56bc8654148bf665a897e9b2f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "766512519550463ebea2da95c5979c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34fac15fe0e84f76bb390ab8cacab040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a48a654a5a7c430793ca82b9e729e85e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e1ec04628724349a431757fb61eca39",
              "IPY_MODEL_dfd4d82f5f9a414f921a186a1ff7e811"
            ]
          }
        },
        "a48a654a5a7c430793ca82b9e729e85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e1ec04628724349a431757fb61eca39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_608da62015c44d3e91516376eec9f324",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 531146902,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 531146902,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1aa82c43abe940149d2791c7e5b6f85c"
          }
        },
        "dfd4d82f5f9a414f921a186a1ff7e811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df3011f011fc454eb379b6d306d6789d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 531M/531M [00:12&lt;00:00, 44.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1b80bb9e3bc413eaa337b762f98c6cb"
          }
        },
        "608da62015c44d3e91516376eec9f324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1aa82c43abe940149d2791c7e5b6f85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df3011f011fc454eb379b6d306d6789d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1b80bb9e3bc413eaa337b762f98c6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE1kSAf-OKGN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8vMBSYLRFrB"
      },
      "source": [
        "!tar -xf /content/TreebankWydzwieku2.0.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDmzU5qvOR1W"
      },
      "source": [
        "data_names = [\"jun18\", \"neg\", \"polevaltest\", \"rev\", \"sklad\"]\n",
        "def create_dataset(data_names):\n",
        "  all_sentences = []\n",
        "  all_labels = []\n",
        "  all_parents = []\n",
        "  for name in data_names:\n",
        "    with open('/content/TreebankWydzwieku2.0/' + name + '_sentence.txt', \"r\") as f:\n",
        "      sentences = [line.rstrip(\"\\n\") for line in f]\n",
        "    with open('/content/TreebankWydzwieku2.0/' + name + '_labels.txt', \"r\") as f:\n",
        "      labels = [line.rstrip(\"\\n\") for line in f]\n",
        "    with open('/content/TreebankWydzwieku2.0/' + name + '_parents.txt', \"r\") as f:\n",
        "      parents = [line.rstrip(\"\\n\") for line in f] \n",
        "    \n",
        "    all_sentences = all_sentences + sentences\n",
        "    all_labels = all_labels + labels\n",
        "    all_parents = all_parents + parents\n",
        "\n",
        "  data = pd.DataFrame([all_sentences, all_labels, all_parents]).T\n",
        "  data.columns = [\"Sentences\", \"Labels\", \"Parents\"]\n",
        "  \n",
        "  return data\n",
        "\n",
        "treebank_data = create_dataset(data_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hTq4O_wQqmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0155397-9d66-4a3f-d5bd-9b2beae90207"
      },
      "source": [
        "len(treebank_data.Sentences[0].split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObAhORnepXJq",
        "outputId": "15608539-fdea-43ff-91da-ab151732e1a8"
      },
      "source": [
        "len(treebank_data.Labels[0].split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSi_DHMxpdkq",
        "outputId": "12f09d6a-912c-4a16-e789-81ce822632ca"
      },
      "source": [
        "treebank_data.Parents[0].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2',\n",
              " '3',\n",
              " '5',\n",
              " '3',\n",
              " '11',\n",
              " '7',\n",
              " '5',\n",
              " '7',\n",
              " '7',\n",
              " '11',\n",
              " '0',\n",
              " '17',\n",
              " '12',\n",
              " '17',\n",
              " '14',\n",
              " '17',\n",
              " '11',\n",
              " '17',\n",
              " '11']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF1QKElEQxsP"
      },
      "source": [
        "def rescale_sentiment(data):\n",
        "  out = []\n",
        "  for row in data.itertuples():\n",
        "    idx = np.where(np.array(row.Parents.split()) == '0')[0][0]\n",
        "    sentence_sentiment = int(row.Labels.split()[idx])\n",
        "\n",
        "    if sentence_sentiment == 0:\n",
        "      sentence_sentiment = 2\n",
        "    elif sentence_sentiment == -1:\n",
        "      sentence_sentiment = 0\n",
        "      \n",
        "    out.append([row.Sentences, sentence_sentiment])\n",
        "\n",
        "  return pd.DataFrame(out, columns=[\"opinia\", \"sentyment\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9cjLfVDMsfAC",
        "outputId": "044addac-a4a9-4c12-b519-54ceacde33ec"
      },
      "source": [
        "treebank_data = rescale_sentiment(treebank_data)\n",
        "treebank_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opinia</th>\n",
              "      <th>sentyment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sam burger był dobry , oczywiście jadła m leps...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mięso średnio wysmażone , bardzo soczyste , ar...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sama kompozycja grillowana wołowina z powidłam...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Widzę niepochlebne opinie o obsłudze z którymi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ceny nieco wygórowane jak na warunki lubelskie...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              opinia  sentyment\n",
              "0  Sam burger był dobry , oczywiście jadła m leps...          2\n",
              "1  Mięso średnio wysmażone , bardzo soczyste , ar...          2\n",
              "2  Sama kompozycja grillowana wołowina z powidłam...          2\n",
              "3  Widzę niepochlebne opinie o obsłudze z którymi...          1\n",
              "4  Ceny nieco wygórowane jak na warunki lubelskie...          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioqZ3MzvTr0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7b2fe2-cced-42bb-cae8-712952e362d7"
      },
      "source": [
        "treebank_data.sentyment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1798\n",
              "1     392\n",
              "0     361\n",
              "Name: sentyment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4h7TK28WKkc"
      },
      "source": [
        "!pip install transformers==2.8.0 -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKQQsKOUWN3n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-17m5paWQLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af513e8d-562c-477d-b540-cef1f28e0c66"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "#model.cuda()\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNmDVRq5WSZm"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "X = treebank_data.opinia.to_numpy()\n",
        "y = treebank_data.sentyment.to_numpy()\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  train_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  train_labels, test_labels = y[train_index], y[test_index]\n",
        "\n",
        "X = test_sentences\n",
        "y = test_labels\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  dev_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  dev_labels, test_labels = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGAymyseWmWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdfd187-7e19-4d56-bbae-a541ecb08c04"
      },
      "source": [
        "print('Train data')\n",
        "print(len(train_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Dev data')\n",
        "print(len(dev_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Test data')\n",
        "print(len(test_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data\n",
            "0.6997255978047824\n",
            "Dev data\n",
            "0.21011368090944726\n",
            "Test data\n",
            "0.09016072128577028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpO6uu8Q20Cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb59d8c-f6e6-4ddb-dfd9-735393ec87e3"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ2IBNFH2Xkb"
      },
      "source": [
        "dev_treebank_data = pd.DataFrame([dev_sentences,dev_labels]).T\n",
        "test_treebank_data = pd.DataFrame([test_sentences,test_labels]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5MDukmT2cLA"
      },
      "source": [
        "dev_treebank_data.to_csv('/content/drive/My Drive/dev_treebank_data_preprocessed.csv')\n",
        "test_treebank_data.to_csv('/content/drive/My Drive/test_treebank_data_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsyL60gzWnS8"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "X = train_sentences\n",
        "y = train_labels\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  train_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  train_labels, test_labels = y[train_index], y[test_index]\n",
        "\n",
        "X = test_sentences\n",
        "y = test_labels\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  dev_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  dev_labels, test_labels = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I16BeE-yWpgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185f1009-d58e-40a0-dbb7-fd6490e03258"
      },
      "source": [
        "print('Train data')\n",
        "print(len(train_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Dev data')\n",
        "print(len(dev_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Test data')\n",
        "print(len(test_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data\n",
            "0.8\n",
            "Dev data\n",
            "0.09971988795518208\n",
            "Test data\n",
            "0.10028011204481793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzHMCdvqWrfp"
      },
      "source": [
        "# Remove long sentences.\n",
        "# TO-DO Possible cut?\n",
        "def remove_big(sentences, labels):\n",
        "  to_remove = []\n",
        "  for i, sent in enumerate(sentences):\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True) # TO-DO: add_special_tokens\n",
        "      if len(input_ids) > MAX_LEN:\n",
        "        to_remove.append(i)\n",
        "\n",
        "  sentences = np.delete(sentences, to_remove)\n",
        "  labels = np.delete(labels, to_remove) \n",
        "\n",
        "  print('{} samples removed.'.format(len(to_remove)))\n",
        "\n",
        "  return sentences, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CadMsoeWusR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "92e932741b244f0cb813eb976c9a8500",
            "723d14334454472f8697d32944e830e0",
            "0bef6dd8abca49208241b19ad5e859fb",
            "c50d7b2a8a844e1a82a70215c0828f45",
            "5b9c3df12d194fc794bd9ab2ceaed200",
            "73b2aaf31e0e490baf0b79a808ae1e5b",
            "6bff0a1037b243b28ab08dd04ac8b22c",
            "f5e5df874608482888e2f5ebb0650725",
            "753c5785b7f6434db7f042c8a0300e59",
            "687730fe7f7441a0a4ec65ff5c7411b4",
            "4e4e0d3b47564a0abf822029624aaee5",
            "af0cc2f8864b4d9a96c0f6d92d69bbc7",
            "1c38f533eec54f598cfaa0f66b3a9fc1",
            "2d75519bfae346788fcfefd75c81185a",
            "e2575951bab84d959772753e445789e9",
            "af212f10dfd6465588cfe9eba87a8c52",
            "9b805013d1614fa7be3050e87446bf02",
            "48de3ea7e6aa4fe1917aab20be9d5ad5",
            "2675a037becc4cab932b1aed347d1a44",
            "8e75207a9c2d498487b5c4a124bff036",
            "bfb70593b23448b3a21c610b8a991c0d",
            "56c8f1871b8449e0977c046b8fd190ab",
            "25b76bfc00c74b7cb73ac76af6516010",
            "b0e04cf8be9648219b3e03e1453ac946"
          ]
        },
        "outputId": "b9ed866e-42f8-4031-e396-08064499ecf8"
      },
      "source": [
        "# Downloading tokenizer\n",
        "# From Polbert - Polish BERT by Darek Kłeczek: https://github.com/kldarek/polbert\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92e932741b244f0cb813eb976c9a8500",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=494801.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "753c5785b7f6434db7f042c8a0300e59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b805013d1614fa7be3050e87446bf02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t6F7nXoWws1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81534de1-79c0-4467-948f-a3bdacbc202a"
      },
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "train_sentences, train_labels = remove_big(train_sentences, train_labels)\n",
        "test_sentences, test_labels = remove_big(test_sentences, test_labels)\n",
        "dev_sentences, dev_labels = remove_big(dev_sentences, dev_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 samples removed.\n",
            "0 samples removed.\n",
            "0 samples removed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qmtIVRGWyeG"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "# Create TensorDatasets for train/dev/test sets\n",
        "def tensor_dataset(sentences, labels):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  for sent in sentences:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                     \n",
        "                          add_special_tokens = True,\n",
        "                          max_length = MAX_LEN,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sLx-LknW0fP"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataset = tensor_dataset(train_sentences, train_labels)\n",
        "test_dataset = tensor_dataset(test_sentences, test_labels)\n",
        "dev_dataset = tensor_dataset(dev_sentences, dev_labels)\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "# Create the DataLoaders for train/dev/test sets.\n",
        "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = BATCH_SIZE)\n",
        "validation_dataloader = DataLoader(dev_dataset, sampler = SequentialSampler(dev_dataset), batch_size = BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM1aedPnW3BW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1bb2ac401411408981cbb866947017b2",
            "5ecb349e65bf4a9f8c181fb7a6cae589",
            "9850f8abe62a4cc198350687b185d4d4",
            "b9b1e59a612943f8b12a2510a416e4dc",
            "12cd14a17b854c41a648fa5d8615d13c",
            "d1ea0b0cf8d14d45a800761b474ecde5",
            "a21ba56bc8654148bf665a897e9b2f01",
            "766512519550463ebea2da95c5979c60",
            "34fac15fe0e84f76bb390ab8cacab040",
            "a48a654a5a7c430793ca82b9e729e85e",
            "6e1ec04628724349a431757fb61eca39",
            "dfd4d82f5f9a414f921a186a1ff7e811",
            "608da62015c44d3e91516376eec9f324",
            "1aa82c43abe940149d2791c7e5b6f85c",
            "df3011f011fc454eb379b6d306d6789d",
            "f1b80bb9e3bc413eaa337b762f98c6cb"
          ]
        },
        "outputId": "d92753d0-f9c3-4fcf-aec8-afb0d2f9dc71"
      },
      "source": [
        "# Load model with a sequence classification head\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dkleczek/bert-base-polish-uncased-v1\", # Polbert - Polish BERT by Darek Kłeczek: https://github.com/kldarek/polbert\n",
        "    num_labels = 3,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb2ac401411408981cbb866947017b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=459.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34fac15fe0e84f76bb390ab8cacab040",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=531146902.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(60000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYws2JGNW8us",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377c52c4-eb83-437f-d6d3-afef55265143"
      },
      "source": [
        "import time, datetime\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.optimization import AdamW\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Takes a time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round((elapsed)))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# Parameters:\n",
        "epochs = 3\n",
        "#lr = 3e-3 # Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "lr = 3e-5 # Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "adam_epsilon = 1e-8\n",
        "WARM_UP = 0.1\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = lr, eps = adam_epsilon)\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = WARM_UP, num_training_steps = total_steps)\n",
        "\n",
        "train_loss_values = []\n",
        "dev_acc_values = []\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch_i in range(0, epochs):  \n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  # https://github.com/huggingface/transformers/blob/master/examples/run_glue.py\n",
        "  # linie 168-183\n",
        "  epoch_train_loss = 0 # Cumulative loss\n",
        "  loss = 0 ;     batch_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    elapsed = format_time(time.time() - t0)      \n",
        "    # Report progress.\n",
        "    print('  Batch {:>5,}  of  {:>5,}. Loss: {:.3f}  Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "    \n",
        "\n",
        "    batch_loss = 0\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)    \n",
        "\n",
        "    # clear any previously calculated gradients before backward pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "    epoch_train_loss += loss.item()\n",
        "    batch_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n",
        "    optimizer.step()\n",
        "    scheduler.step()  # Update learning rate schedule\n",
        "\n",
        "  epoch_train_loss = epoch_train_loss / len(train_dataloader)          \n",
        "  train_loss_values.append(epoch_train_loss)\n",
        "  \n",
        "  print('Average training loss: {0:.2f}'.format(epoch_train_loss))\n",
        "\n",
        "  # Evaluation\n",
        "  total_eval_accuracy = 0\n",
        "  model.eval()\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    \n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_masks = batch[1].to(device)\n",
        "    labels = batch[2].to('cpu').numpy()\n",
        "                \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    predictions = np.argmax(logits, axis=1).flatten()\n",
        "    total_eval_accuracy += flat_accuracy(logits, labels)\n",
        "\n",
        "  avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "  print(\"  Accuracy: {0:.4f}\".format(avg_val_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch     0  of    179. Loss: 0.000  Elapsed: 0:00:00.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch     1  of    179. Loss: 1.312  Elapsed: 0:00:00.\n",
            "  Batch     2  of    179. Loss: 1.095  Elapsed: 0:00:01.\n",
            "  Batch     3  of    179. Loss: 1.076  Elapsed: 0:00:01.\n",
            "  Batch     4  of    179. Loss: 1.122  Elapsed: 0:00:01.\n",
            "  Batch     5  of    179. Loss: 0.927  Elapsed: 0:00:01.\n",
            "  Batch     6  of    179. Loss: 0.891  Elapsed: 0:00:01.\n",
            "  Batch     7  of    179. Loss: 0.857  Elapsed: 0:00:02.\n",
            "  Batch     8  of    179. Loss: 0.909  Elapsed: 0:00:02.\n",
            "  Batch     9  of    179. Loss: 0.879  Elapsed: 0:00:02.\n",
            "  Batch    10  of    179. Loss: 1.179  Elapsed: 0:00:02.\n",
            "  Batch    11  of    179. Loss: 0.413  Elapsed: 0:00:02.\n",
            "  Batch    12  of    179. Loss: 0.513  Elapsed: 0:00:03.\n",
            "  Batch    13  of    179. Loss: 0.686  Elapsed: 0:00:03.\n",
            "  Batch    14  of    179. Loss: 0.738  Elapsed: 0:00:03.\n",
            "  Batch    15  of    179. Loss: 0.794  Elapsed: 0:00:03.\n",
            "  Batch    16  of    179. Loss: 0.793  Elapsed: 0:00:03.\n",
            "  Batch    17  of    179. Loss: 0.671  Elapsed: 0:00:04.\n",
            "  Batch    18  of    179. Loss: 0.932  Elapsed: 0:00:04.\n",
            "  Batch    19  of    179. Loss: 0.453  Elapsed: 0:00:04.\n",
            "  Batch    20  of    179. Loss: 0.670  Elapsed: 0:00:04.\n",
            "  Batch    21  of    179. Loss: 0.463  Elapsed: 0:00:04.\n",
            "  Batch    22  of    179. Loss: 0.900  Elapsed: 0:00:05.\n",
            "  Batch    23  of    179. Loss: 0.620  Elapsed: 0:00:05.\n",
            "  Batch    24  of    179. Loss: 0.847  Elapsed: 0:00:05.\n",
            "  Batch    25  of    179. Loss: 1.091  Elapsed: 0:00:05.\n",
            "  Batch    26  of    179. Loss: 0.702  Elapsed: 0:00:06.\n",
            "  Batch    27  of    179. Loss: 0.469  Elapsed: 0:00:06.\n",
            "  Batch    28  of    179. Loss: 0.922  Elapsed: 0:00:06.\n",
            "  Batch    29  of    179. Loss: 0.992  Elapsed: 0:00:06.\n",
            "  Batch    30  of    179. Loss: 0.554  Elapsed: 0:00:06.\n",
            "  Batch    31  of    179. Loss: 1.106  Elapsed: 0:00:07.\n",
            "  Batch    32  of    179. Loss: 0.936  Elapsed: 0:00:07.\n",
            "  Batch    33  of    179. Loss: 0.814  Elapsed: 0:00:07.\n",
            "  Batch    34  of    179. Loss: 0.593  Elapsed: 0:00:07.\n",
            "  Batch    35  of    179. Loss: 0.965  Elapsed: 0:00:07.\n",
            "  Batch    36  of    179. Loss: 0.801  Elapsed: 0:00:08.\n",
            "  Batch    37  of    179. Loss: 0.872  Elapsed: 0:00:08.\n",
            "  Batch    38  of    179. Loss: 0.932  Elapsed: 0:00:08.\n",
            "  Batch    39  of    179. Loss: 0.872  Elapsed: 0:00:08.\n",
            "  Batch    40  of    179. Loss: 1.255  Elapsed: 0:00:09.\n",
            "  Batch    41  of    179. Loss: 1.210  Elapsed: 0:00:09.\n",
            "  Batch    42  of    179. Loss: 0.672  Elapsed: 0:00:09.\n",
            "  Batch    43  of    179. Loss: 0.849  Elapsed: 0:00:09.\n",
            "  Batch    44  of    179. Loss: 0.809  Elapsed: 0:00:09.\n",
            "  Batch    45  of    179. Loss: 0.826  Elapsed: 0:00:10.\n",
            "  Batch    46  of    179. Loss: 0.530  Elapsed: 0:00:10.\n",
            "  Batch    47  of    179. Loss: 0.342  Elapsed: 0:00:10.\n",
            "  Batch    48  of    179. Loss: 0.942  Elapsed: 0:00:10.\n",
            "  Batch    49  of    179. Loss: 0.681  Elapsed: 0:00:10.\n",
            "  Batch    50  of    179. Loss: 0.702  Elapsed: 0:00:11.\n",
            "  Batch    51  of    179. Loss: 0.681  Elapsed: 0:00:11.\n",
            "  Batch    52  of    179. Loss: 0.575  Elapsed: 0:00:11.\n",
            "  Batch    53  of    179. Loss: 0.933  Elapsed: 0:00:11.\n",
            "  Batch    54  of    179. Loss: 0.671  Elapsed: 0:00:11.\n",
            "  Batch    55  of    179. Loss: 0.570  Elapsed: 0:00:12.\n",
            "  Batch    56  of    179. Loss: 0.518  Elapsed: 0:00:12.\n",
            "  Batch    57  of    179. Loss: 0.507  Elapsed: 0:00:12.\n",
            "  Batch    58  of    179. Loss: 0.639  Elapsed: 0:00:12.\n",
            "  Batch    59  of    179. Loss: 0.509  Elapsed: 0:00:13.\n",
            "  Batch    60  of    179. Loss: 0.724  Elapsed: 0:00:13.\n",
            "  Batch    61  of    179. Loss: 0.710  Elapsed: 0:00:13.\n",
            "  Batch    62  of    179. Loss: 1.021  Elapsed: 0:00:13.\n",
            "  Batch    63  of    179. Loss: 0.457  Elapsed: 0:00:13.\n",
            "  Batch    64  of    179. Loss: 0.395  Elapsed: 0:00:14.\n",
            "  Batch    65  of    179. Loss: 0.727  Elapsed: 0:00:14.\n",
            "  Batch    66  of    179. Loss: 0.356  Elapsed: 0:00:14.\n",
            "  Batch    67  of    179. Loss: 0.345  Elapsed: 0:00:14.\n",
            "  Batch    68  of    179. Loss: 0.326  Elapsed: 0:00:14.\n",
            "  Batch    69  of    179. Loss: 0.685  Elapsed: 0:00:15.\n",
            "  Batch    70  of    179. Loss: 0.624  Elapsed: 0:00:15.\n",
            "  Batch    71  of    179. Loss: 0.516  Elapsed: 0:00:15.\n",
            "  Batch    72  of    179. Loss: 0.234  Elapsed: 0:00:15.\n",
            "  Batch    73  of    179. Loss: 0.741  Elapsed: 0:00:16.\n",
            "  Batch    74  of    179. Loss: 0.883  Elapsed: 0:00:16.\n",
            "  Batch    75  of    179. Loss: 1.161  Elapsed: 0:00:16.\n",
            "  Batch    76  of    179. Loss: 0.870  Elapsed: 0:00:16.\n",
            "  Batch    77  of    179. Loss: 0.712  Elapsed: 0:00:16.\n",
            "  Batch    78  of    179. Loss: 0.351  Elapsed: 0:00:17.\n",
            "  Batch    79  of    179. Loss: 1.471  Elapsed: 0:00:17.\n",
            "  Batch    80  of    179. Loss: 0.732  Elapsed: 0:00:17.\n",
            "  Batch    81  of    179. Loss: 0.576  Elapsed: 0:00:17.\n",
            "  Batch    82  of    179. Loss: 0.542  Elapsed: 0:00:17.\n",
            "  Batch    83  of    179. Loss: 0.624  Elapsed: 0:00:18.\n",
            "  Batch    84  of    179. Loss: 0.898  Elapsed: 0:00:18.\n",
            "  Batch    85  of    179. Loss: 0.575  Elapsed: 0:00:18.\n",
            "  Batch    86  of    179. Loss: 0.567  Elapsed: 0:00:18.\n",
            "  Batch    87  of    179. Loss: 0.602  Elapsed: 0:00:18.\n",
            "  Batch    88  of    179. Loss: 0.658  Elapsed: 0:00:19.\n",
            "  Batch    89  of    179. Loss: 0.368  Elapsed: 0:00:19.\n",
            "  Batch    90  of    179. Loss: 0.564  Elapsed: 0:00:19.\n",
            "  Batch    91  of    179. Loss: 0.674  Elapsed: 0:00:19.\n",
            "  Batch    92  of    179. Loss: 0.747  Elapsed: 0:00:20.\n",
            "  Batch    93  of    179. Loss: 0.871  Elapsed: 0:00:20.\n",
            "  Batch    94  of    179. Loss: 0.851  Elapsed: 0:00:20.\n",
            "  Batch    95  of    179. Loss: 0.936  Elapsed: 0:00:20.\n",
            "  Batch    96  of    179. Loss: 0.242  Elapsed: 0:00:20.\n",
            "  Batch    97  of    179. Loss: 0.896  Elapsed: 0:00:21.\n",
            "  Batch    98  of    179. Loss: 0.410  Elapsed: 0:00:21.\n",
            "  Batch    99  of    179. Loss: 0.359  Elapsed: 0:00:21.\n",
            "  Batch   100  of    179. Loss: 0.224  Elapsed: 0:00:21.\n",
            "  Batch   101  of    179. Loss: 0.680  Elapsed: 0:00:21.\n",
            "  Batch   102  of    179. Loss: 0.777  Elapsed: 0:00:22.\n",
            "  Batch   103  of    179. Loss: 0.667  Elapsed: 0:00:22.\n",
            "  Batch   104  of    179. Loss: 0.746  Elapsed: 0:00:22.\n",
            "  Batch   105  of    179. Loss: 0.963  Elapsed: 0:00:22.\n",
            "  Batch   106  of    179. Loss: 0.425  Elapsed: 0:00:23.\n",
            "  Batch   107  of    179. Loss: 0.504  Elapsed: 0:00:23.\n",
            "  Batch   108  of    179. Loss: 0.524  Elapsed: 0:00:23.\n",
            "  Batch   109  of    179. Loss: 0.443  Elapsed: 0:00:23.\n",
            "  Batch   110  of    179. Loss: 1.107  Elapsed: 0:00:23.\n",
            "  Batch   111  of    179. Loss: 0.438  Elapsed: 0:00:24.\n",
            "  Batch   112  of    179. Loss: 0.790  Elapsed: 0:00:24.\n",
            "  Batch   113  of    179. Loss: 1.050  Elapsed: 0:00:24.\n",
            "  Batch   114  of    179. Loss: 0.754  Elapsed: 0:00:24.\n",
            "  Batch   115  of    179. Loss: 0.455  Elapsed: 0:00:24.\n",
            "  Batch   116  of    179. Loss: 0.774  Elapsed: 0:00:25.\n",
            "  Batch   117  of    179. Loss: 0.616  Elapsed: 0:00:25.\n",
            "  Batch   118  of    179. Loss: 0.696  Elapsed: 0:00:25.\n",
            "  Batch   119  of    179. Loss: 0.661  Elapsed: 0:00:25.\n",
            "  Batch   120  of    179. Loss: 0.820  Elapsed: 0:00:26.\n",
            "  Batch   121  of    179. Loss: 0.393  Elapsed: 0:00:26.\n",
            "  Batch   122  of    179. Loss: 0.759  Elapsed: 0:00:26.\n",
            "  Batch   123  of    179. Loss: 0.620  Elapsed: 0:00:26.\n",
            "  Batch   124  of    179. Loss: 1.231  Elapsed: 0:00:26.\n",
            "  Batch   125  of    179. Loss: 0.793  Elapsed: 0:00:27.\n",
            "  Batch   126  of    179. Loss: 0.702  Elapsed: 0:00:27.\n",
            "  Batch   127  of    179. Loss: 0.460  Elapsed: 0:00:27.\n",
            "  Batch   128  of    179. Loss: 0.664  Elapsed: 0:00:27.\n",
            "  Batch   129  of    179. Loss: 0.747  Elapsed: 0:00:27.\n",
            "  Batch   130  of    179. Loss: 0.496  Elapsed: 0:00:28.\n",
            "  Batch   131  of    179. Loss: 0.494  Elapsed: 0:00:28.\n",
            "  Batch   132  of    179. Loss: 0.815  Elapsed: 0:00:28.\n",
            "  Batch   133  of    179. Loss: 0.517  Elapsed: 0:00:28.\n",
            "  Batch   134  of    179. Loss: 0.301  Elapsed: 0:00:29.\n",
            "  Batch   135  of    179. Loss: 0.825  Elapsed: 0:00:29.\n",
            "  Batch   136  of    179. Loss: 0.594  Elapsed: 0:00:29.\n",
            "  Batch   137  of    179. Loss: 0.584  Elapsed: 0:00:29.\n",
            "  Batch   138  of    179. Loss: 0.314  Elapsed: 0:00:29.\n",
            "  Batch   139  of    179. Loss: 1.078  Elapsed: 0:00:30.\n",
            "  Batch   140  of    179. Loss: 0.257  Elapsed: 0:00:30.\n",
            "  Batch   141  of    179. Loss: 0.268  Elapsed: 0:00:30.\n",
            "  Batch   142  of    179. Loss: 0.358  Elapsed: 0:00:30.\n",
            "  Batch   143  of    179. Loss: 1.207  Elapsed: 0:00:30.\n",
            "  Batch   144  of    179. Loss: 0.999  Elapsed: 0:00:31.\n",
            "  Batch   145  of    179. Loss: 0.782  Elapsed: 0:00:31.\n",
            "  Batch   146  of    179. Loss: 0.590  Elapsed: 0:00:31.\n",
            "  Batch   147  of    179. Loss: 0.387  Elapsed: 0:00:31.\n",
            "  Batch   148  of    179. Loss: 0.505  Elapsed: 0:00:32.\n",
            "  Batch   149  of    179. Loss: 1.167  Elapsed: 0:00:32.\n",
            "  Batch   150  of    179. Loss: 0.473  Elapsed: 0:00:32.\n",
            "  Batch   151  of    179. Loss: 0.512  Elapsed: 0:00:32.\n",
            "  Batch   152  of    179. Loss: 0.931  Elapsed: 0:00:32.\n",
            "  Batch   153  of    179. Loss: 0.829  Elapsed: 0:00:33.\n",
            "  Batch   154  of    179. Loss: 0.602  Elapsed: 0:00:33.\n",
            "  Batch   155  of    179. Loss: 0.586  Elapsed: 0:00:33.\n",
            "  Batch   156  of    179. Loss: 0.916  Elapsed: 0:00:33.\n",
            "  Batch   157  of    179. Loss: 0.820  Elapsed: 0:00:33.\n",
            "  Batch   158  of    179. Loss: 0.456  Elapsed: 0:00:34.\n",
            "  Batch   159  of    179. Loss: 0.559  Elapsed: 0:00:34.\n",
            "  Batch   160  of    179. Loss: 0.427  Elapsed: 0:00:34.\n",
            "  Batch   161  of    179. Loss: 0.786  Elapsed: 0:00:34.\n",
            "  Batch   162  of    179. Loss: 0.563  Elapsed: 0:00:35.\n",
            "  Batch   163  of    179. Loss: 0.340  Elapsed: 0:00:35.\n",
            "  Batch   164  of    179. Loss: 0.839  Elapsed: 0:00:35.\n",
            "  Batch   165  of    179. Loss: 0.622  Elapsed: 0:00:35.\n",
            "  Batch   166  of    179. Loss: 0.641  Elapsed: 0:00:35.\n",
            "  Batch   167  of    179. Loss: 0.942  Elapsed: 0:00:36.\n",
            "  Batch   168  of    179. Loss: 0.569  Elapsed: 0:00:36.\n",
            "  Batch   169  of    179. Loss: 0.481  Elapsed: 0:00:36.\n",
            "  Batch   170  of    179. Loss: 0.427  Elapsed: 0:00:36.\n",
            "  Batch   171  of    179. Loss: 0.566  Elapsed: 0:00:36.\n",
            "  Batch   172  of    179. Loss: 0.666  Elapsed: 0:00:37.\n",
            "  Batch   173  of    179. Loss: 0.638  Elapsed: 0:00:37.\n",
            "  Batch   174  of    179. Loss: 0.902  Elapsed: 0:00:37.\n",
            "  Batch   175  of    179. Loss: 0.731  Elapsed: 0:00:37.\n",
            "  Batch   176  of    179. Loss: 0.762  Elapsed: 0:00:38.\n",
            "  Batch   177  of    179. Loss: 0.525  Elapsed: 0:00:38.\n",
            "  Batch   178  of    179. Loss: 0.784  Elapsed: 0:00:38.\n",
            "Average training loss: 0.70\n",
            "  Accuracy: 0.7500\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch     0  of    179. Loss: 0.000  Elapsed: 0:00:40.\n",
            "  Batch     1  of    179. Loss: 0.334  Elapsed: 0:00:40.\n",
            "  Batch     2  of    179. Loss: 0.451  Elapsed: 0:00:40.\n",
            "  Batch     3  of    179. Loss: 0.594  Elapsed: 0:00:40.\n",
            "  Batch     4  of    179. Loss: 0.494  Elapsed: 0:00:40.\n",
            "  Batch     5  of    179. Loss: 0.786  Elapsed: 0:00:41.\n",
            "  Batch     6  of    179. Loss: 0.153  Elapsed: 0:00:41.\n",
            "  Batch     7  of    179. Loss: 0.176  Elapsed: 0:00:41.\n",
            "  Batch     8  of    179. Loss: 0.361  Elapsed: 0:00:41.\n",
            "  Batch     9  of    179. Loss: 0.345  Elapsed: 0:00:41.\n",
            "  Batch    10  of    179. Loss: 0.179  Elapsed: 0:00:42.\n",
            "  Batch    11  of    179. Loss: 0.273  Elapsed: 0:00:42.\n",
            "  Batch    12  of    179. Loss: 0.696  Elapsed: 0:00:42.\n",
            "  Batch    13  of    179. Loss: 0.587  Elapsed: 0:00:42.\n",
            "  Batch    14  of    179. Loss: 0.321  Elapsed: 0:00:43.\n",
            "  Batch    15  of    179. Loss: 0.845  Elapsed: 0:00:43.\n",
            "  Batch    16  of    179. Loss: 0.880  Elapsed: 0:00:43.\n",
            "  Batch    17  of    179. Loss: 0.626  Elapsed: 0:00:43.\n",
            "  Batch    18  of    179. Loss: 0.588  Elapsed: 0:00:43.\n",
            "  Batch    19  of    179. Loss: 0.350  Elapsed: 0:00:44.\n",
            "  Batch    20  of    179. Loss: 0.200  Elapsed: 0:00:44.\n",
            "  Batch    21  of    179. Loss: 0.578  Elapsed: 0:00:44.\n",
            "  Batch    22  of    179. Loss: 0.305  Elapsed: 0:00:44.\n",
            "  Batch    23  of    179. Loss: 0.307  Elapsed: 0:00:45.\n",
            "  Batch    24  of    179. Loss: 0.196  Elapsed: 0:00:45.\n",
            "  Batch    25  of    179. Loss: 0.215  Elapsed: 0:00:45.\n",
            "  Batch    26  of    179. Loss: 0.702  Elapsed: 0:00:45.\n",
            "  Batch    27  of    179. Loss: 0.449  Elapsed: 0:00:45.\n",
            "  Batch    28  of    179. Loss: 0.543  Elapsed: 0:00:46.\n",
            "  Batch    29  of    179. Loss: 0.263  Elapsed: 0:00:46.\n",
            "  Batch    30  of    179. Loss: 0.349  Elapsed: 0:00:46.\n",
            "  Batch    31  of    179. Loss: 0.516  Elapsed: 0:00:46.\n",
            "  Batch    32  of    179. Loss: 0.728  Elapsed: 0:00:47.\n",
            "  Batch    33  of    179. Loss: 0.172  Elapsed: 0:00:47.\n",
            "  Batch    34  of    179. Loss: 0.807  Elapsed: 0:00:47.\n",
            "  Batch    35  of    179. Loss: 0.277  Elapsed: 0:00:47.\n",
            "  Batch    36  of    179. Loss: 0.461  Elapsed: 0:00:47.\n",
            "  Batch    37  of    179. Loss: 1.163  Elapsed: 0:00:48.\n",
            "  Batch    38  of    179. Loss: 0.372  Elapsed: 0:00:48.\n",
            "  Batch    39  of    179. Loss: 0.321  Elapsed: 0:00:48.\n",
            "  Batch    40  of    179. Loss: 0.606  Elapsed: 0:00:48.\n",
            "  Batch    41  of    179. Loss: 0.682  Elapsed: 0:00:48.\n",
            "  Batch    42  of    179. Loss: 0.481  Elapsed: 0:00:49.\n",
            "  Batch    43  of    179. Loss: 0.508  Elapsed: 0:00:49.\n",
            "  Batch    44  of    179. Loss: 0.426  Elapsed: 0:00:49.\n",
            "  Batch    45  of    179. Loss: 0.525  Elapsed: 0:00:49.\n",
            "  Batch    46  of    179. Loss: 0.631  Elapsed: 0:00:50.\n",
            "  Batch    47  of    179. Loss: 0.192  Elapsed: 0:00:50.\n",
            "  Batch    48  of    179. Loss: 0.438  Elapsed: 0:00:50.\n",
            "  Batch    49  of    179. Loss: 0.269  Elapsed: 0:00:50.\n",
            "  Batch    50  of    179. Loss: 0.486  Elapsed: 0:00:50.\n",
            "  Batch    51  of    179. Loss: 0.236  Elapsed: 0:00:51.\n",
            "  Batch    52  of    179. Loss: 0.373  Elapsed: 0:00:51.\n",
            "  Batch    53  of    179. Loss: 0.268  Elapsed: 0:00:51.\n",
            "  Batch    54  of    179. Loss: 0.417  Elapsed: 0:00:51.\n",
            "  Batch    55  of    179. Loss: 0.498  Elapsed: 0:00:52.\n",
            "  Batch    56  of    179. Loss: 0.104  Elapsed: 0:00:52.\n",
            "  Batch    57  of    179. Loss: 0.217  Elapsed: 0:00:52.\n",
            "  Batch    58  of    179. Loss: 0.326  Elapsed: 0:00:52.\n",
            "  Batch    59  of    179. Loss: 0.417  Elapsed: 0:00:52.\n",
            "  Batch    60  of    179. Loss: 0.595  Elapsed: 0:00:53.\n",
            "  Batch    61  of    179. Loss: 0.721  Elapsed: 0:00:53.\n",
            "  Batch    62  of    179. Loss: 0.177  Elapsed: 0:00:53.\n",
            "  Batch    63  of    179. Loss: 1.147  Elapsed: 0:00:53.\n",
            "  Batch    64  of    179. Loss: 0.404  Elapsed: 0:00:54.\n",
            "  Batch    65  of    179. Loss: 0.449  Elapsed: 0:00:54.\n",
            "  Batch    66  of    179. Loss: 0.620  Elapsed: 0:00:54.\n",
            "  Batch    67  of    179. Loss: 0.717  Elapsed: 0:00:54.\n",
            "  Batch    68  of    179. Loss: 0.665  Elapsed: 0:00:54.\n",
            "  Batch    69  of    179. Loss: 0.098  Elapsed: 0:00:55.\n",
            "  Batch    70  of    179. Loss: 0.559  Elapsed: 0:00:55.\n",
            "  Batch    71  of    179. Loss: 0.506  Elapsed: 0:00:55.\n",
            "  Batch    72  of    179. Loss: 1.005  Elapsed: 0:00:55.\n",
            "  Batch    73  of    179. Loss: 0.206  Elapsed: 0:00:56.\n",
            "  Batch    74  of    179. Loss: 0.255  Elapsed: 0:00:56.\n",
            "  Batch    75  of    179. Loss: 0.203  Elapsed: 0:00:56.\n",
            "  Batch    76  of    179. Loss: 0.102  Elapsed: 0:00:56.\n",
            "  Batch    77  of    179. Loss: 0.562  Elapsed: 0:00:56.\n",
            "  Batch    78  of    179. Loss: 0.694  Elapsed: 0:00:57.\n",
            "  Batch    79  of    179. Loss: 0.379  Elapsed: 0:00:57.\n",
            "  Batch    80  of    179. Loss: 0.248  Elapsed: 0:00:57.\n",
            "  Batch    81  of    179. Loss: 0.455  Elapsed: 0:00:57.\n",
            "  Batch    82  of    179. Loss: 0.304  Elapsed: 0:00:57.\n",
            "  Batch    83  of    179. Loss: 0.199  Elapsed: 0:00:58.\n",
            "  Batch    84  of    179. Loss: 0.614  Elapsed: 0:00:58.\n",
            "  Batch    85  of    179. Loss: 0.773  Elapsed: 0:00:58.\n",
            "  Batch    86  of    179. Loss: 0.179  Elapsed: 0:00:58.\n",
            "  Batch    87  of    179. Loss: 0.878  Elapsed: 0:00:59.\n",
            "  Batch    88  of    179. Loss: 0.379  Elapsed: 0:00:59.\n",
            "  Batch    89  of    179. Loss: 0.487  Elapsed: 0:00:59.\n",
            "  Batch    90  of    179. Loss: 0.239  Elapsed: 0:00:59.\n",
            "  Batch    91  of    179. Loss: 0.345  Elapsed: 0:00:59.\n",
            "  Batch    92  of    179. Loss: 0.967  Elapsed: 0:01:00.\n",
            "  Batch    93  of    179. Loss: 0.742  Elapsed: 0:01:00.\n",
            "  Batch    94  of    179. Loss: 0.151  Elapsed: 0:01:00.\n",
            "  Batch    95  of    179. Loss: 0.140  Elapsed: 0:01:00.\n",
            "  Batch    96  of    179. Loss: 0.341  Elapsed: 0:01:01.\n",
            "  Batch    97  of    179. Loss: 0.244  Elapsed: 0:01:01.\n",
            "  Batch    98  of    179. Loss: 0.231  Elapsed: 0:01:01.\n",
            "  Batch    99  of    179. Loss: 0.777  Elapsed: 0:01:01.\n",
            "  Batch   100  of    179. Loss: 0.458  Elapsed: 0:01:01.\n",
            "  Batch   101  of    179. Loss: 0.539  Elapsed: 0:01:02.\n",
            "  Batch   102  of    179. Loss: 0.194  Elapsed: 0:01:02.\n",
            "  Batch   103  of    179. Loss: 0.268  Elapsed: 0:01:02.\n",
            "  Batch   104  of    179. Loss: 0.035  Elapsed: 0:01:02.\n",
            "  Batch   105  of    179. Loss: 0.343  Elapsed: 0:01:03.\n",
            "  Batch   106  of    179. Loss: 0.338  Elapsed: 0:01:03.\n",
            "  Batch   107  of    179. Loss: 0.084  Elapsed: 0:01:03.\n",
            "  Batch   108  of    179. Loss: 0.205  Elapsed: 0:01:03.\n",
            "  Batch   109  of    179. Loss: 0.246  Elapsed: 0:01:03.\n",
            "  Batch   110  of    179. Loss: 0.158  Elapsed: 0:01:04.\n",
            "  Batch   111  of    179. Loss: 0.284  Elapsed: 0:01:04.\n",
            "  Batch   112  of    179. Loss: 0.265  Elapsed: 0:01:04.\n",
            "  Batch   113  of    179. Loss: 0.789  Elapsed: 0:01:04.\n",
            "  Batch   114  of    179. Loss: 0.958  Elapsed: 0:01:05.\n",
            "  Batch   115  of    179. Loss: 0.768  Elapsed: 0:01:05.\n",
            "  Batch   116  of    179. Loss: 0.178  Elapsed: 0:01:05.\n",
            "  Batch   117  of    179. Loss: 0.298  Elapsed: 0:01:05.\n",
            "  Batch   118  of    179. Loss: 0.190  Elapsed: 0:01:05.\n",
            "  Batch   119  of    179. Loss: 0.318  Elapsed: 0:01:06.\n",
            "  Batch   120  of    179. Loss: 0.561  Elapsed: 0:01:06.\n",
            "  Batch   121  of    179. Loss: 0.153  Elapsed: 0:01:06.\n",
            "  Batch   122  of    179. Loss: 0.138  Elapsed: 0:01:06.\n",
            "  Batch   123  of    179. Loss: 0.748  Elapsed: 0:01:07.\n",
            "  Batch   124  of    179. Loss: 0.321  Elapsed: 0:01:07.\n",
            "  Batch   125  of    179. Loss: 0.350  Elapsed: 0:01:07.\n",
            "  Batch   126  of    179. Loss: 0.356  Elapsed: 0:01:07.\n",
            "  Batch   127  of    179. Loss: 0.675  Elapsed: 0:01:07.\n",
            "  Batch   128  of    179. Loss: 0.268  Elapsed: 0:01:08.\n",
            "  Batch   129  of    179. Loss: 0.476  Elapsed: 0:01:08.\n",
            "  Batch   130  of    179. Loss: 0.214  Elapsed: 0:01:08.\n",
            "  Batch   131  of    179. Loss: 0.399  Elapsed: 0:01:08.\n",
            "  Batch   132  of    179. Loss: 0.343  Elapsed: 0:01:09.\n",
            "  Batch   133  of    179. Loss: 0.328  Elapsed: 0:01:09.\n",
            "  Batch   134  of    179. Loss: 0.257  Elapsed: 0:01:09.\n",
            "  Batch   135  of    179. Loss: 0.509  Elapsed: 0:01:09.\n",
            "  Batch   136  of    179. Loss: 0.796  Elapsed: 0:01:10.\n",
            "  Batch   137  of    179. Loss: 0.223  Elapsed: 0:01:10.\n",
            "  Batch   138  of    179. Loss: 0.822  Elapsed: 0:01:10.\n",
            "  Batch   139  of    179. Loss: 0.132  Elapsed: 0:01:10.\n",
            "  Batch   140  of    179. Loss: 0.460  Elapsed: 0:01:10.\n",
            "  Batch   141  of    179. Loss: 0.304  Elapsed: 0:01:11.\n",
            "  Batch   142  of    179. Loss: 0.213  Elapsed: 0:01:11.\n",
            "  Batch   143  of    179. Loss: 0.160  Elapsed: 0:01:11.\n",
            "  Batch   144  of    179. Loss: 0.121  Elapsed: 0:01:11.\n",
            "  Batch   145  of    179. Loss: 0.237  Elapsed: 0:01:12.\n",
            "  Batch   146  of    179. Loss: 0.183  Elapsed: 0:01:12.\n",
            "  Batch   147  of    179. Loss: 0.210  Elapsed: 0:01:12.\n",
            "  Batch   148  of    179. Loss: 0.515  Elapsed: 0:01:12.\n",
            "  Batch   149  of    179. Loss: 0.176  Elapsed: 0:01:12.\n",
            "  Batch   150  of    179. Loss: 0.992  Elapsed: 0:01:13.\n",
            "  Batch   151  of    179. Loss: 0.219  Elapsed: 0:01:13.\n",
            "  Batch   152  of    179. Loss: 0.655  Elapsed: 0:01:13.\n",
            "  Batch   153  of    179. Loss: 0.244  Elapsed: 0:01:13.\n",
            "  Batch   154  of    179. Loss: 0.655  Elapsed: 0:01:14.\n",
            "  Batch   155  of    179. Loss: 0.251  Elapsed: 0:01:14.\n",
            "  Batch   156  of    179. Loss: 1.099  Elapsed: 0:01:14.\n",
            "  Batch   157  of    179. Loss: 0.263  Elapsed: 0:01:14.\n",
            "  Batch   158  of    179. Loss: 0.171  Elapsed: 0:01:14.\n",
            "  Batch   159  of    179. Loss: 0.755  Elapsed: 0:01:15.\n",
            "  Batch   160  of    179. Loss: 0.896  Elapsed: 0:01:15.\n",
            "  Batch   161  of    179. Loss: 0.818  Elapsed: 0:01:15.\n",
            "  Batch   162  of    179. Loss: 0.113  Elapsed: 0:01:15.\n",
            "  Batch   163  of    179. Loss: 0.221  Elapsed: 0:01:16.\n",
            "  Batch   164  of    179. Loss: 0.116  Elapsed: 0:01:16.\n",
            "  Batch   165  of    179. Loss: 0.177  Elapsed: 0:01:16.\n",
            "  Batch   166  of    179. Loss: 0.073  Elapsed: 0:01:16.\n",
            "  Batch   167  of    179. Loss: 0.082  Elapsed: 0:01:16.\n",
            "  Batch   168  of    179. Loss: 0.115  Elapsed: 0:01:17.\n",
            "  Batch   169  of    179. Loss: 0.162  Elapsed: 0:01:17.\n",
            "  Batch   170  of    179. Loss: 0.419  Elapsed: 0:01:17.\n",
            "  Batch   171  of    179. Loss: 0.271  Elapsed: 0:01:17.\n",
            "  Batch   172  of    179. Loss: 0.298  Elapsed: 0:01:18.\n",
            "  Batch   173  of    179. Loss: 0.649  Elapsed: 0:01:18.\n",
            "  Batch   174  of    179. Loss: 0.139  Elapsed: 0:01:18.\n",
            "  Batch   175  of    179. Loss: 0.272  Elapsed: 0:01:18.\n",
            "  Batch   176  of    179. Loss: 0.097  Elapsed: 0:01:19.\n",
            "  Batch   177  of    179. Loss: 0.626  Elapsed: 0:01:19.\n",
            "  Batch   178  of    179. Loss: 0.246  Elapsed: 0:01:19.\n",
            "Average training loss: 0.41\n",
            "  Accuracy: 0.7500\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch     0  of    179. Loss: 0.000  Elapsed: 0:01:21.\n",
            "  Batch     1  of    179. Loss: 0.134  Elapsed: 0:01:21.\n",
            "  Batch     2  of    179. Loss: 0.062  Elapsed: 0:01:21.\n",
            "  Batch     3  of    179. Loss: 0.054  Elapsed: 0:01:21.\n",
            "  Batch     4  of    179. Loss: 0.722  Elapsed: 0:01:22.\n",
            "  Batch     5  of    179. Loss: 0.440  Elapsed: 0:01:22.\n",
            "  Batch     6  of    179. Loss: 0.405  Elapsed: 0:01:22.\n",
            "  Batch     7  of    179. Loss: 0.104  Elapsed: 0:01:22.\n",
            "  Batch     8  of    179. Loss: 0.309  Elapsed: 0:01:22.\n",
            "  Batch     9  of    179. Loss: 0.439  Elapsed: 0:01:23.\n",
            "  Batch    10  of    179. Loss: 0.131  Elapsed: 0:01:23.\n",
            "  Batch    11  of    179. Loss: 0.070  Elapsed: 0:01:23.\n",
            "  Batch    12  of    179. Loss: 0.123  Elapsed: 0:01:23.\n",
            "  Batch    13  of    179. Loss: 0.070  Elapsed: 0:01:24.\n",
            "  Batch    14  of    179. Loss: 0.284  Elapsed: 0:01:24.\n",
            "  Batch    15  of    179. Loss: 0.093  Elapsed: 0:01:24.\n",
            "  Batch    16  of    179. Loss: 0.112  Elapsed: 0:01:24.\n",
            "  Batch    17  of    179. Loss: 0.079  Elapsed: 0:01:25.\n",
            "  Batch    18  of    179. Loss: 0.059  Elapsed: 0:01:25.\n",
            "  Batch    19  of    179. Loss: 0.052  Elapsed: 0:01:25.\n",
            "  Batch    20  of    179. Loss: 0.040  Elapsed: 0:01:25.\n",
            "  Batch    21  of    179. Loss: 0.078  Elapsed: 0:01:25.\n",
            "  Batch    22  of    179. Loss: 0.036  Elapsed: 0:01:26.\n",
            "  Batch    23  of    179. Loss: 0.077  Elapsed: 0:01:26.\n",
            "  Batch    24  of    179. Loss: 0.057  Elapsed: 0:01:26.\n",
            "  Batch    25  of    179. Loss: 0.052  Elapsed: 0:01:26.\n",
            "  Batch    26  of    179. Loss: 0.358  Elapsed: 0:01:27.\n",
            "  Batch    27  of    179. Loss: 0.233  Elapsed: 0:01:27.\n",
            "  Batch    28  of    179. Loss: 0.063  Elapsed: 0:01:27.\n",
            "  Batch    29  of    179. Loss: 0.086  Elapsed: 0:01:27.\n",
            "  Batch    30  of    179. Loss: 0.021  Elapsed: 0:01:28.\n",
            "  Batch    31  of    179. Loss: 0.035  Elapsed: 0:01:28.\n",
            "  Batch    32  of    179. Loss: 0.216  Elapsed: 0:01:28.\n",
            "  Batch    33  of    179. Loss: 0.118  Elapsed: 0:01:28.\n",
            "  Batch    34  of    179. Loss: 0.027  Elapsed: 0:01:28.\n",
            "  Batch    35  of    179. Loss: 0.016  Elapsed: 0:01:29.\n",
            "  Batch    36  of    179. Loss: 0.038  Elapsed: 0:01:29.\n",
            "  Batch    37  of    179. Loss: 0.293  Elapsed: 0:01:29.\n",
            "  Batch    38  of    179. Loss: 0.051  Elapsed: 0:01:29.\n",
            "  Batch    39  of    179. Loss: 0.460  Elapsed: 0:01:30.\n",
            "  Batch    40  of    179. Loss: 0.025  Elapsed: 0:01:30.\n",
            "  Batch    41  of    179. Loss: 0.498  Elapsed: 0:01:30.\n",
            "  Batch    42  of    179. Loss: 0.078  Elapsed: 0:01:30.\n",
            "  Batch    43  of    179. Loss: 0.163  Elapsed: 0:01:31.\n",
            "  Batch    44  of    179. Loss: 0.221  Elapsed: 0:01:31.\n",
            "  Batch    45  of    179. Loss: 0.217  Elapsed: 0:01:31.\n",
            "  Batch    46  of    179. Loss: 0.436  Elapsed: 0:01:31.\n",
            "  Batch    47  of    179. Loss: 0.613  Elapsed: 0:01:31.\n",
            "  Batch    48  of    179. Loss: 0.384  Elapsed: 0:01:32.\n",
            "  Batch    49  of    179. Loss: 0.168  Elapsed: 0:01:32.\n",
            "  Batch    50  of    179. Loss: 0.126  Elapsed: 0:01:32.\n",
            "  Batch    51  of    179. Loss: 0.128  Elapsed: 0:01:32.\n",
            "  Batch    52  of    179. Loss: 0.077  Elapsed: 0:01:33.\n",
            "  Batch    53  of    179. Loss: 0.187  Elapsed: 0:01:33.\n",
            "  Batch    54  of    179. Loss: 0.080  Elapsed: 0:01:33.\n",
            "  Batch    55  of    179. Loss: 0.664  Elapsed: 0:01:33.\n",
            "  Batch    56  of    179. Loss: 0.653  Elapsed: 0:01:34.\n",
            "  Batch    57  of    179. Loss: 0.056  Elapsed: 0:01:34.\n",
            "  Batch    58  of    179. Loss: 0.035  Elapsed: 0:01:34.\n",
            "  Batch    59  of    179. Loss: 0.035  Elapsed: 0:01:34.\n",
            "  Batch    60  of    179. Loss: 0.038  Elapsed: 0:01:34.\n",
            "  Batch    61  of    179. Loss: 0.408  Elapsed: 0:01:35.\n",
            "  Batch    62  of    179. Loss: 0.053  Elapsed: 0:01:35.\n",
            "  Batch    63  of    179. Loss: 0.086  Elapsed: 0:01:35.\n",
            "  Batch    64  of    179. Loss: 0.077  Elapsed: 0:01:35.\n",
            "  Batch    65  of    179. Loss: 0.033  Elapsed: 0:01:36.\n",
            "  Batch    66  of    179. Loss: 0.065  Elapsed: 0:01:36.\n",
            "  Batch    67  of    179. Loss: 0.119  Elapsed: 0:01:36.\n",
            "  Batch    68  of    179. Loss: 0.742  Elapsed: 0:01:36.\n",
            "  Batch    69  of    179. Loss: 0.150  Elapsed: 0:01:37.\n",
            "  Batch    70  of    179. Loss: 0.121  Elapsed: 0:01:37.\n",
            "  Batch    71  of    179. Loss: 0.067  Elapsed: 0:01:37.\n",
            "  Batch    72  of    179. Loss: 0.029  Elapsed: 0:01:37.\n",
            "  Batch    73  of    179. Loss: 0.015  Elapsed: 0:01:38.\n",
            "  Batch    74  of    179. Loss: 0.058  Elapsed: 0:01:38.\n",
            "  Batch    75  of    179. Loss: 0.502  Elapsed: 0:01:38.\n",
            "  Batch    76  of    179. Loss: 0.043  Elapsed: 0:01:38.\n",
            "  Batch    77  of    179. Loss: 0.124  Elapsed: 0:01:38.\n",
            "  Batch    78  of    179. Loss: 0.208  Elapsed: 0:01:39.\n",
            "  Batch    79  of    179. Loss: 0.056  Elapsed: 0:01:39.\n",
            "  Batch    80  of    179. Loss: 0.017  Elapsed: 0:01:39.\n",
            "  Batch    81  of    179. Loss: 0.342  Elapsed: 0:01:39.\n",
            "  Batch    82  of    179. Loss: 0.046  Elapsed: 0:01:40.\n",
            "  Batch    83  of    179. Loss: 0.361  Elapsed: 0:01:40.\n",
            "  Batch    84  of    179. Loss: 0.052  Elapsed: 0:01:40.\n",
            "  Batch    85  of    179. Loss: 0.311  Elapsed: 0:01:40.\n",
            "  Batch    86  of    179. Loss: 0.195  Elapsed: 0:01:41.\n",
            "  Batch    87  of    179. Loss: 0.078  Elapsed: 0:01:41.\n",
            "  Batch    88  of    179. Loss: 0.042  Elapsed: 0:01:41.\n",
            "  Batch    89  of    179. Loss: 0.099  Elapsed: 0:01:41.\n",
            "  Batch    90  of    179. Loss: 0.053  Elapsed: 0:01:42.\n",
            "  Batch    91  of    179. Loss: 0.031  Elapsed: 0:01:42.\n",
            "  Batch    92  of    179. Loss: 0.034  Elapsed: 0:01:42.\n",
            "  Batch    93  of    179. Loss: 0.173  Elapsed: 0:01:42.\n",
            "  Batch    94  of    179. Loss: 0.013  Elapsed: 0:01:42.\n",
            "  Batch    95  of    179. Loss: 0.219  Elapsed: 0:01:43.\n",
            "  Batch    96  of    179. Loss: 0.518  Elapsed: 0:01:43.\n",
            "  Batch    97  of    179. Loss: 0.376  Elapsed: 0:01:43.\n",
            "  Batch    98  of    179. Loss: 0.126  Elapsed: 0:01:43.\n",
            "  Batch    99  of    179. Loss: 0.016  Elapsed: 0:01:44.\n",
            "  Batch   100  of    179. Loss: 0.077  Elapsed: 0:01:44.\n",
            "  Batch   101  of    179. Loss: 0.047  Elapsed: 0:01:44.\n",
            "  Batch   102  of    179. Loss: 0.047  Elapsed: 0:01:44.\n",
            "  Batch   103  of    179. Loss: 0.262  Elapsed: 0:01:45.\n",
            "  Batch   104  of    179. Loss: 0.327  Elapsed: 0:01:45.\n",
            "  Batch   105  of    179. Loss: 0.119  Elapsed: 0:01:45.\n",
            "  Batch   106  of    179. Loss: 0.358  Elapsed: 0:01:45.\n",
            "  Batch   107  of    179. Loss: 0.075  Elapsed: 0:01:46.\n",
            "  Batch   108  of    179. Loss: 0.062  Elapsed: 0:01:46.\n",
            "  Batch   109  of    179. Loss: 0.252  Elapsed: 0:01:46.\n",
            "  Batch   110  of    179. Loss: 0.015  Elapsed: 0:01:46.\n",
            "  Batch   111  of    179. Loss: 0.696  Elapsed: 0:01:46.\n",
            "  Batch   112  of    179. Loss: 0.047  Elapsed: 0:01:47.\n",
            "  Batch   113  of    179. Loss: 0.275  Elapsed: 0:01:47.\n",
            "  Batch   114  of    179. Loss: 0.618  Elapsed: 0:01:47.\n",
            "  Batch   115  of    179. Loss: 0.243  Elapsed: 0:01:47.\n",
            "  Batch   116  of    179. Loss: 0.357  Elapsed: 0:01:48.\n",
            "  Batch   117  of    179. Loss: 0.024  Elapsed: 0:01:48.\n",
            "  Batch   118  of    179. Loss: 0.428  Elapsed: 0:01:48.\n",
            "  Batch   119  of    179. Loss: 0.048  Elapsed: 0:01:48.\n",
            "  Batch   120  of    179. Loss: 0.025  Elapsed: 0:01:49.\n",
            "  Batch   121  of    179. Loss: 1.253  Elapsed: 0:01:49.\n",
            "  Batch   122  of    179. Loss: 0.018  Elapsed: 0:01:49.\n",
            "  Batch   123  of    179. Loss: 0.170  Elapsed: 0:01:49.\n",
            "  Batch   124  of    179. Loss: 0.017  Elapsed: 0:01:50.\n",
            "  Batch   125  of    179. Loss: 0.052  Elapsed: 0:01:50.\n",
            "  Batch   126  of    179. Loss: 0.028  Elapsed: 0:01:50.\n",
            "  Batch   127  of    179. Loss: 0.009  Elapsed: 0:01:50.\n",
            "  Batch   128  of    179. Loss: 0.116  Elapsed: 0:01:51.\n",
            "  Batch   129  of    179. Loss: 0.440  Elapsed: 0:01:51.\n",
            "  Batch   130  of    179. Loss: 0.080  Elapsed: 0:01:51.\n",
            "  Batch   131  of    179. Loss: 0.571  Elapsed: 0:01:51.\n",
            "  Batch   132  of    179. Loss: 0.066  Elapsed: 0:01:52.\n",
            "  Batch   133  of    179. Loss: 0.185  Elapsed: 0:01:52.\n",
            "  Batch   134  of    179. Loss: 0.016  Elapsed: 0:01:52.\n",
            "  Batch   135  of    179. Loss: 0.375  Elapsed: 0:01:52.\n",
            "  Batch   136  of    179. Loss: 0.026  Elapsed: 0:01:52.\n",
            "  Batch   137  of    179. Loss: 0.431  Elapsed: 0:01:53.\n",
            "  Batch   138  of    179. Loss: 0.107  Elapsed: 0:01:53.\n",
            "  Batch   139  of    179. Loss: 0.042  Elapsed: 0:01:53.\n",
            "  Batch   140  of    179. Loss: 0.394  Elapsed: 0:01:53.\n",
            "  Batch   141  of    179. Loss: 0.020  Elapsed: 0:01:54.\n",
            "  Batch   142  of    179. Loss: 0.020  Elapsed: 0:01:54.\n",
            "  Batch   143  of    179. Loss: 0.219  Elapsed: 0:01:54.\n",
            "  Batch   144  of    179. Loss: 0.061  Elapsed: 0:01:54.\n",
            "  Batch   145  of    179. Loss: 0.067  Elapsed: 0:01:55.\n",
            "  Batch   146  of    179. Loss: 0.013  Elapsed: 0:01:55.\n",
            "  Batch   147  of    179. Loss: 0.530  Elapsed: 0:01:55.\n",
            "  Batch   148  of    179. Loss: 0.093  Elapsed: 0:01:55.\n",
            "  Batch   149  of    179. Loss: 0.032  Elapsed: 0:01:56.\n",
            "  Batch   150  of    179. Loss: 0.049  Elapsed: 0:01:56.\n",
            "  Batch   151  of    179. Loss: 0.213  Elapsed: 0:01:56.\n",
            "  Batch   152  of    179. Loss: 0.637  Elapsed: 0:01:56.\n",
            "  Batch   153  of    179. Loss: 0.011  Elapsed: 0:01:57.\n",
            "  Batch   154  of    179. Loss: 0.071  Elapsed: 0:01:57.\n",
            "  Batch   155  of    179. Loss: 0.018  Elapsed: 0:01:57.\n",
            "  Batch   156  of    179. Loss: 0.074  Elapsed: 0:01:57.\n",
            "  Batch   157  of    179. Loss: 0.041  Elapsed: 0:01:57.\n",
            "  Batch   158  of    179. Loss: 0.103  Elapsed: 0:01:58.\n",
            "  Batch   159  of    179. Loss: 0.270  Elapsed: 0:01:58.\n",
            "  Batch   160  of    179. Loss: 0.168  Elapsed: 0:01:58.\n",
            "  Batch   161  of    179. Loss: 0.029  Elapsed: 0:01:58.\n",
            "  Batch   162  of    179. Loss: 0.062  Elapsed: 0:01:59.\n",
            "  Batch   163  of    179. Loss: 0.271  Elapsed: 0:01:59.\n",
            "  Batch   164  of    179. Loss: 0.083  Elapsed: 0:01:59.\n",
            "  Batch   165  of    179. Loss: 0.233  Elapsed: 0:01:59.\n",
            "  Batch   166  of    179. Loss: 0.166  Elapsed: 0:02:00.\n",
            "  Batch   167  of    179. Loss: 0.025  Elapsed: 0:02:00.\n",
            "  Batch   168  of    179. Loss: 0.019  Elapsed: 0:02:00.\n",
            "  Batch   169  of    179. Loss: 0.242  Elapsed: 0:02:00.\n",
            "  Batch   170  of    179. Loss: 0.090  Elapsed: 0:02:01.\n",
            "  Batch   171  of    179. Loss: 0.194  Elapsed: 0:02:01.\n",
            "  Batch   172  of    179. Loss: 0.016  Elapsed: 0:02:01.\n",
            "  Batch   173  of    179. Loss: 0.143  Elapsed: 0:02:01.\n",
            "  Batch   174  of    179. Loss: 0.064  Elapsed: 0:02:02.\n",
            "  Batch   175  of    179. Loss: 0.121  Elapsed: 0:02:02.\n",
            "  Batch   176  of    179. Loss: 0.099  Elapsed: 0:02:02.\n",
            "  Batch   177  of    179. Loss: 0.210  Elapsed: 0:02:02.\n",
            "  Batch   178  of    179. Loss: 0.291  Elapsed: 0:02:02.\n",
            "Average training loss: 0.18\n",
            "  Accuracy: 0.7554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_EDpZb4W9hQ"
      },
      "source": [
        "predicted_labels = [] ; true_labels = []; logits_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "  \n",
        "  input_ids = batch[0].to(device)\n",
        "  attention_masks = batch[1].to(device)\n",
        "  labels = batch[2]\n",
        "  \n",
        "  with torch.no_grad():        \n",
        "      outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                  \n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  logits_list.append(logits)\n",
        "  \n",
        "  predictions = np.argmax(logits, axis=1).flatten()\n",
        "  labels = labels.numpy().flatten()\n",
        "\n",
        "  predicted_labels.extend( predictions )\n",
        "  true_labels.extend( labels )\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqxneobOXAgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14815c65-c597-4723-d669-e8a465a5ac21"
      },
      "source": [
        "from sklearn.metrics import classification_report \n",
        "print( classification_report(y_true=true_labels, y_pred=predicted_labels, zero_division=0) ) # 74 61 73 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.48      0.52        25\n",
            "           1       0.61      0.50      0.55        28\n",
            "           2       0.81      0.87      0.84       126\n",
            "\n",
            "    accuracy                           0.75       179\n",
            "   macro avg       0.66      0.62      0.64       179\n",
            "weighted avg       0.74      0.75      0.75       179\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0944gyhiYY2D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ac3f69f-1000-4188-c522-120d8baf43ee"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uql-x0xgYZTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd26698-df6d-4903-9236-e601b6744b53"
      },
      "source": [
        "import os\n",
        "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
        "output_dir = \"/content/drive/My Drive/model_bert_finetuned_4\"\n",
        "\n",
        "# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
        "# If we have a distributed model, save only the encapsulated model\n",
        "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/model_bert_finetuned_4/vocab.txt',\n",
              " '/content/drive/My Drive/model_bert_finetuned_4/special_tokens_map.json',\n",
              " '/content/drive/My Drive/model_bert_finetuned_4/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3exdZM-SYx5R"
      },
      "source": [
        "# Step 2: Re-load the saved model and vocabulary\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppo4uAx_D7T1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
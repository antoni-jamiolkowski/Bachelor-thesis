{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBngsJkm_Qg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e690d5-e57b-49aa-e28f-1f4465386d5f"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqMo0x10G9Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b839fb-6c2d-41c4-bf34-abf397a2b4de"
      },
      "source": [
        "!pip install transformers==2.8.0 -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 573kB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 43.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 52.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 61.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.9MB 48.1MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: botocore 1.19.26 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gf8GG0NYQOq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def metaclassifier_experiment(\n",
        "    train_data_path,\n",
        "    test_data_path,\n",
        "    models_paths,\n",
        "    dropnas=True):\n",
        "  \n",
        "  def tensor_dataset(sentences, labels, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                     \n",
        "                            add_special_tokens = True,\n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return dataset\n",
        "\n",
        "  def inverse_logit(x):\n",
        "    return np.exp(x) / (1 + np.exp(x))\n",
        "\n",
        "  def BERT_inference(model, dataloader):\n",
        "    predicted_probs = []; true_labels = []\n",
        "    model.to(device)\n",
        "    for batch in dataloader:\n",
        "      \n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_masks = batch[1].to(device)\n",
        "      labels = batch[2]\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                      \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predicted_probs.extend(inverse_logit(logits))\n",
        "      \n",
        "      labels = labels.numpy().flatten()\n",
        "      true_labels.extend(labels)\n",
        "\n",
        "    return np.array(predicted_probs), np.array(true_labels)\n",
        "\n",
        "  \n",
        "  if torch.cuda.is_available():    \n",
        "\n",
        "      # Tell PyTorch to use the GPU.    \n",
        "      device = torch.device(\"cuda\")\n",
        "\n",
        "      print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  train_data = pd.read_csv(train_data_path, index_col=0)\n",
        "  test_data = pd.read_csv(test_data_path, index_col=0)\n",
        "  print(\"Loaded data ...\")\n",
        "\n",
        "  if dropnas:\n",
        "      train_data = train_data.dropna()\n",
        "      test_data = test_data.dropna()\n",
        "      print(\"Dropped NAN's ...\")\n",
        "\n",
        "  tokenizers = []\n",
        "  models = []\n",
        "  for i, model_path in enumerate(models_paths):\n",
        "    print(\"Tokenizer %s model ... \" % i)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "    tokenizers.append(tokenizer)\n",
        "    print(\"%s tokenizer loaded!\" % i)\n",
        "    \n",
        "    print(\"Loading %s model ... \" % i)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    models.append(model)\n",
        "    print(\"%s model loaded!\" % i)\n",
        "\n",
        "  models_train_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    train_dataset = tensor_dataset(train_data.iloc[:,0].to_numpy(), train_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler = SequentialSampler(train_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_train_labels = BERT_inference(model, train_dataloader)\n",
        "    \n",
        "    models_train_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "  \n",
        "  meta_train_data = np.concatenate(models_train_output, axis=1)\n",
        "\n",
        "  print(\"Training metaclassifier ...\")\n",
        "  meta_classifier = SVC(kernel='linear')\n",
        "  meta_classifier.fit(meta_train_data, meta_train_labels)\n",
        "  print(\"Metaclassifier trained!\")\n",
        "\n",
        "  models_test_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    test_dataset = tensor_dataset(test_data.iloc[:,0].to_numpy(), test_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_test_labels = BERT_inference(model, test_dataloader)\n",
        "    models_test_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "\n",
        "  meta_test_data = np.concatenate(models_test_output, axis=1)\n",
        "\n",
        "  print(\"Making final prediciton for tests ...\")\n",
        "  meta_test_prediction = meta_classifier.predict(meta_test_data)\n",
        "  \n",
        "  print(classification_report(y_true=meta_test_labels, y_pred=meta_test_prediction, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5tOkcGhd-U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3608f1-da12-47b2-d529-a3f1bdc62841"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_moto_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_moto_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.62      0.64        79\n",
            "           1       0.81      0.82      0.81       149\n",
            "           2       0.54      0.56      0.55        87\n",
            "\n",
            "    accuracy                           0.70       315\n",
            "   macro avg       0.67      0.67      0.67       315\n",
            "weighted avg       0.70      0.70      0.70       315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu8-K4sYov-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a0b103-33de-4458-b27d-2c2dd197440c"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_treebank_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_treebank_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.34      0.42        32\n",
            "           1       0.00      0.00      0.00        36\n",
            "           2       0.73      0.94      0.82       162\n",
            "\n",
            "    accuracy                           0.71       230\n",
            "   macro avg       0.43      0.43      0.42       230\n",
            "weighted avg       0.59      0.71      0.64       230\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-9AHPZ1owii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1483d0-2ca4-425a-c327-0095fe37a047"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_hotels_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_hotels_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92      1033\n",
            "           1       0.90      0.92      0.91       724\n",
            "           2       0.85      0.74      0.79       441\n",
            "\n",
            "    accuracy                           0.89      2198\n",
            "   macro avg       0.88      0.87      0.87      2198\n",
            "weighted avg       0.89      0.89      0.89      2198\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfqcScbr4T9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e072d99-d1bd-41c2-d404-b9a891c4eb3d"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_medicine_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_medicine_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.80       706\n",
            "           1       0.80      0.84      0.82       518\n",
            "           2       0.86      0.83      0.85       888\n",
            "\n",
            "    accuracy                           0.83      2112\n",
            "   macro avg       0.82      0.83      0.82      2112\n",
            "weighted avg       0.83      0.83      0.83      2112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWEfPU_L4UpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa95eab3-85ca-4747-a5a1-abcbe2bf9dc4"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_products_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_products_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90       344\n",
            "           1       0.87      0.86      0.86       194\n",
            "           2       0.74      0.48      0.58        73\n",
            "\n",
            "    accuracy                           0.86       611\n",
            "   macro avg       0.83      0.76      0.78       611\n",
            "weighted avg       0.85      0.86      0.85       611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BszBl51_4VUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e17694e-c71c-4407-e0e3-dc6af08c285e"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_reviews_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_reviews_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.82      0.74        40\n",
            "           1       0.88      0.80      0.84        86\n",
            "           2       0.50      0.47      0.48        17\n",
            "\n",
            "    accuracy                           0.77       143\n",
            "   macro avg       0.69      0.70      0.69       143\n",
            "weighted avg       0.78      0.77      0.77       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxyip6CFowR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e3e792-5a02-428c-c851-bebd76861e43"
      },
      "source": [
        "metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_filmweb_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_filmweb_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.67      0.66        30\n",
            "           1       0.85      0.85      0.85        39\n",
            "           2       0.55      0.53      0.54        30\n",
            "\n",
            "    accuracy                           0.70        99\n",
            "   macro avg       0.68      0.68      0.68        99\n",
            "weighted avg       0.70      0.70      0.70        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtaFHADHg73"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def xgboost_metaclassifier_experiment(\n",
        "    train_data_path,\n",
        "    test_data_path,\n",
        "    models_paths,\n",
        "    dropnas=True):\n",
        "  \n",
        "  def tensor_dataset(sentences, labels, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                     \n",
        "                            add_special_tokens = True,\n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return dataset\n",
        "\n",
        "  def inverse_logit(x):\n",
        "    return np.exp(x) / (1 + np.exp(x))\n",
        "\n",
        "  def BERT_inference(model, dataloader):\n",
        "    predicted_probs = []; true_labels = []\n",
        "    model.to(device)\n",
        "    for batch in dataloader:\n",
        "      \n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_masks = batch[1].to(device)\n",
        "      labels = batch[2]\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                      \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predicted_probs.extend(inverse_logit(logits))\n",
        "      \n",
        "      labels = labels.numpy().flatten()\n",
        "      true_labels.extend(labels)\n",
        "\n",
        "    return np.array(predicted_probs), np.array(true_labels)\n",
        "\n",
        "  \n",
        "  if torch.cuda.is_available():    \n",
        "\n",
        "      # Tell PyTorch to use the GPU.    \n",
        "      device = torch.device(\"cuda\")\n",
        "\n",
        "      print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  train_data = pd.read_csv(train_data_path, index_col=0)\n",
        "  test_data = pd.read_csv(test_data_path, index_col=0)\n",
        "  print(\"Loaded data ...\")\n",
        "\n",
        "  if dropnas:\n",
        "      train_data = train_data.dropna()\n",
        "      test_data = test_data.dropna()\n",
        "      print(\"Dropped NAN's ...\")\n",
        "\n",
        "  tokenizers = []\n",
        "  models = []\n",
        "  for i, model_path in enumerate(models_paths):\n",
        "    print(\"Tokenizer %s model ... \" % i)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "    tokenizers.append(tokenizer)\n",
        "    print(\"%s tokenizer loaded!\" % i)\n",
        "    \n",
        "    print(\"Loading %s model ... \" % i)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    models.append(model)\n",
        "    print(\"%s model loaded!\" % i)\n",
        "\n",
        "  models_train_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    train_dataset = tensor_dataset(train_data.iloc[:,0].to_numpy(), train_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler = SequentialSampler(train_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_train_labels = BERT_inference(model, train_dataloader)\n",
        "    \n",
        "    models_train_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "  \n",
        "  meta_train_data = np.concatenate(models_train_output, axis=1)\n",
        "\n",
        "  print(\"Training metaclassifier ...\")\n",
        "  meta_classifier = XGBClassifier()\n",
        "  meta_classifier.fit(meta_train_data, meta_train_labels)\n",
        "  print(\"Metaclassifier trained!\")\n",
        "\n",
        "  models_test_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    test_dataset = tensor_dataset(test_data.iloc[:,0].to_numpy(), test_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_test_labels = BERT_inference(model, test_dataloader)\n",
        "    models_test_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "\n",
        "  meta_test_data = np.concatenate(models_test_output, axis=1)\n",
        "\n",
        "  print(\"Making final prediciton for tests ...\")\n",
        "  meta_test_prediction = meta_classifier.predict(meta_test_data)\n",
        "  \n",
        "  print(classification_report(y_true=meta_test_labels, y_pred=meta_test_prediction, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8e7iTofI80p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa456293-81cd-4b2d-f74d-f1f0007c49df"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_moto_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_moto_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.62      0.63        79\n",
            "           1       0.82      0.87      0.84       149\n",
            "           2       0.56      0.51      0.53        87\n",
            "\n",
            "    accuracy                           0.71       315\n",
            "   macro avg       0.67      0.67      0.67       315\n",
            "weighted avg       0.70      0.71      0.70       315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSD2DODI9Ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf04f6b4-a608-444a-9658-48a692d7e138"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_treebank_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_treebank_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.34      0.41        32\n",
            "           1       0.60      0.33      0.43        36\n",
            "           2       0.76      0.88      0.82       162\n",
            "\n",
            "    accuracy                           0.72       230\n",
            "   macro avg       0.62      0.52      0.55       230\n",
            "weighted avg       0.70      0.72      0.70       230\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc9hmFZRI9h1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a829a20-43f6-4764-be3e-5bb1a9fa5039"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_hotels_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_hotels_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92      1033\n",
            "           1       0.91      0.91      0.91       724\n",
            "           2       0.87      0.73      0.79       441\n",
            "\n",
            "    accuracy                           0.89      2198\n",
            "   macro avg       0.89      0.86      0.87      2198\n",
            "weighted avg       0.89      0.89      0.89      2198\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFBznRal0z-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fb4f36-7bbd-4afb-c48c-0dda14f95054"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_medicine_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_medicine_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.83       706\n",
            "           1       0.83      0.83      0.83       518\n",
            "           2       0.88      0.84      0.86       888\n",
            "\n",
            "    accuracy                           0.84      2112\n",
            "   macro avg       0.84      0.84      0.84      2112\n",
            "weighted avg       0.84      0.84      0.84      2112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DccV1mO00Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c57921-457f-4d81-b58a-2de4e3c05490"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_products_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_products_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90       344\n",
            "           1       0.87      0.87      0.87       194\n",
            "           2       0.79      0.41      0.54        73\n",
            "\n",
            "    accuracy                           0.86       611\n",
            "   macro avg       0.84      0.74      0.77       611\n",
            "weighted avg       0.85      0.86      0.85       611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46jvD8Pi00kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38788d6-9518-439d-9778-d179107687aa"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_polemo_reviews_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_reviews_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.82      0.76        40\n",
            "           1       0.88      0.84      0.86        86\n",
            "           2       0.50      0.41      0.45        17\n",
            "\n",
            "    accuracy                           0.78       143\n",
            "   macro avg       0.69      0.69      0.69       143\n",
            "weighted avg       0.78      0.78      0.78       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSL59gKII92h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812ea54d-1aa3-482c-b9bb-123df8e0799b"
      },
      "source": [
        "xgboost_metaclassifier_experiment(\n",
        "    train_data_path = '/content/drive/My Drive/dev_filmweb_data_preprocessed.csv',\n",
        "    test_data_path = '/content/drive/My Drive/test_filmweb_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Training metaclassifier ...\n",
            "Metaclassifier trained!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Making final prediciton for tests ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.67      0.66        30\n",
            "           1       0.77      0.87      0.82        39\n",
            "           2       0.54      0.43      0.48        30\n",
            "\n",
            "    accuracy                           0.68        99\n",
            "   macro avg       0.65      0.66      0.65        99\n",
            "weighted avg       0.66      0.68      0.67        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYtjncyFpTIq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def majority_voting_experiment(\n",
        "    test_data_path,\n",
        "    models_paths,\n",
        "    dropnas=True):\n",
        "  \n",
        "  def tensor_dataset(sentences, labels, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                     \n",
        "                            add_special_tokens = True,\n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return dataset\n",
        "\n",
        "  def inverse_logit(x):\n",
        "    return np.exp(x) / (1 + np.exp(x))\n",
        "\n",
        "  def BERT_inference(model, dataloader):\n",
        "    predicted_probs = []; true_labels = []\n",
        "    model.to(device)\n",
        "    for batch in dataloader:\n",
        "      \n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_masks = batch[1].to(device)\n",
        "      labels = batch[2]\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                      \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predicted_probs.extend(inverse_logit(logits))\n",
        "      \n",
        "      labels = labels.numpy().flatten()\n",
        "      true_labels.extend(labels)\n",
        "\n",
        "    return np.array(predicted_probs), np.array(true_labels)\n",
        "\n",
        "  \n",
        "  if torch.cuda.is_available():    \n",
        "\n",
        "      # Tell PyTorch to use the GPU.    \n",
        "      device = torch.device(\"cuda\")\n",
        "\n",
        "      print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  test_data = pd.read_csv(test_data_path, index_col=0)\n",
        "  print(\"Loaded data ...\")\n",
        "  \n",
        "  if dropnas:\n",
        "      test_data = test_data.dropna()\n",
        "      print(\"Dropped NAN's ...\")\n",
        "\n",
        "  tokenizers = []\n",
        "  models = []\n",
        "  for i, model_path in enumerate(models_paths):\n",
        "    print(\"Tokenizer %s model ... \" % i)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "    tokenizers.append(tokenizer)\n",
        "    print(\"%s tokenizer loaded!\" % i)\n",
        "    \n",
        "    print(\"Loading %s model ... \" % i)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    models.append(model)\n",
        "    print(\"%s model loaded!\" % i)\n",
        "\n",
        "  models_test_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    test_dataset = tensor_dataset(test_data.iloc[:,0].to_numpy(), test_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_test_labels = BERT_inference(model, test_dataloader)\n",
        "    models_test_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "\n",
        "  for aggregation_function in [np.min, np.max, np.median]:\n",
        "    print(aggregation_function)\n",
        "    print(\"Making aggregation ...\")\n",
        "    meta_test_data = aggregation_function(np.array(models_test_output), axis=0)\n",
        "    print(\"Aggregation finished ...\")\n",
        "\n",
        "    print(\"Making final prediciton for tests ...\")\n",
        "    meta_test_prediction = np.argmax(meta_test_data, axis=1)\n",
        "    \n",
        "    print(aggregation_function)\n",
        "    print(classification_report(y_true=meta_test_labels, y_pred=meta_test_prediction, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiHEAM3AuyWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afcbb84-e8cd-45fb-aecd-7c17e587b8f4"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_moto_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.71      0.50        79\n",
            "           1       0.70      0.48      0.57       149\n",
            "           2       0.26      0.21      0.23        87\n",
            "\n",
            "    accuracy                           0.46       315\n",
            "   macro avg       0.45      0.47      0.44       315\n",
            "weighted avg       0.50      0.46      0.46       315\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.71      0.47        79\n",
            "           1       0.73      0.56      0.63       149\n",
            "           2       0.33      0.16      0.22        87\n",
            "\n",
            "    accuracy                           0.49       315\n",
            "   macro avg       0.47      0.48      0.44       315\n",
            "weighted avg       0.52      0.49      0.48       315\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.73      0.54        79\n",
            "           1       0.74      0.66      0.70       149\n",
            "           2       0.44      0.24      0.31        87\n",
            "\n",
            "    accuracy                           0.56       315\n",
            "   macro avg       0.54      0.54      0.52       315\n",
            "weighted avg       0.58      0.56      0.55       315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe3zaahTufuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039490df-d643-4807-a51a-5a9d454ef4d2"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_treebank_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.94      0.57        32\n",
            "           1       0.25      0.86      0.38        36\n",
            "           2       0.87      0.16      0.27       162\n",
            "\n",
            "    accuracy                           0.38       230\n",
            "   macro avg       0.51      0.65      0.41       230\n",
            "weighted avg       0.71      0.38      0.33       230\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.91      0.51        32\n",
            "           1       0.26      0.83      0.40        36\n",
            "           2       0.91      0.19      0.31       162\n",
            "\n",
            "    accuracy                           0.39       230\n",
            "   macro avg       0.51      0.64      0.40       230\n",
            "weighted avg       0.73      0.39      0.35       230\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.72      0.51        32\n",
            "           1       0.26      0.86      0.40        36\n",
            "           2       0.76      0.24      0.37       162\n",
            "\n",
            "    accuracy                           0.40       230\n",
            "   macro avg       0.47      0.61      0.42       230\n",
            "weighted avg       0.63      0.40      0.39       230\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBiHVtr-1Z0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddeeb9e-c56b-4b3b-f10d-143059d6f995"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_hotels_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.88      1033\n",
            "           1       0.87      0.85      0.86       724\n",
            "           2       0.67      0.82      0.74       441\n",
            "\n",
            "    accuracy                           0.85      2198\n",
            "   macro avg       0.82      0.84      0.83      2198\n",
            "weighted avg       0.86      0.85      0.85      2198\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.87      0.90      1033\n",
            "           1       0.91      0.87      0.89       724\n",
            "           2       0.69      0.82      0.75       441\n",
            "\n",
            "    accuracy                           0.86      2198\n",
            "   macro avg       0.84      0.86      0.85      2198\n",
            "weighted avg       0.87      0.86      0.87      2198\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.71      0.81      1033\n",
            "           1       0.88      0.85      0.86       724\n",
            "           2       0.53      0.87      0.66       441\n",
            "\n",
            "    accuracy                           0.79      2198\n",
            "   macro avg       0.79      0.81      0.78      2198\n",
            "weighted avg       0.84      0.79      0.80      2198\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eUhCN3A1aEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b83ccdc-a546-4cc0-852b-4c9ad7c4d17b"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_medicine_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.85      0.79       706\n",
            "           1       0.86      0.70      0.77       518\n",
            "           2       0.80      0.79      0.79       888\n",
            "\n",
            "    accuracy                           0.79      2112\n",
            "   macro avg       0.80      0.78      0.78      2112\n",
            "weighted avg       0.79      0.79      0.79      2112\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.88      0.79       706\n",
            "           1       0.84      0.76      0.80       518\n",
            "           2       0.88      0.78      0.83       888\n",
            "\n",
            "    accuracy                           0.81      2112\n",
            "   macro avg       0.82      0.81      0.81      2112\n",
            "weighted avg       0.82      0.81      0.81      2112\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77       706\n",
            "           1       0.83      0.69      0.75       518\n",
            "           2       0.76      0.81      0.79       888\n",
            "\n",
            "    accuracy                           0.77      2112\n",
            "   macro avg       0.78      0.76      0.77      2112\n",
            "weighted avg       0.78      0.77      0.77      2112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYNFkx6p1aUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7b77ef-c7a3-4917-d6f5-1bcc20bc59ad"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_products_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.83       344\n",
            "           1       0.89      0.72      0.79       194\n",
            "           2       0.36      0.68      0.47        73\n",
            "\n",
            "    accuracy                           0.76       611\n",
            "   macro avg       0.71      0.73      0.70       611\n",
            "weighted avg       0.81      0.76      0.78       611\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       344\n",
            "           1       0.92      0.65      0.77       194\n",
            "           2       0.29      0.68      0.40        73\n",
            "\n",
            "    accuracy                           0.70       611\n",
            "   macro avg       0.68      0.69      0.65       611\n",
            "weighted avg       0.80      0.70      0.73       611\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.63      0.75       344\n",
            "           1       0.91      0.66      0.77       194\n",
            "           2       0.26      0.82      0.39        73\n",
            "\n",
            "    accuracy                           0.66       611\n",
            "   macro avg       0.69      0.71      0.64       611\n",
            "weighted avg       0.83      0.66      0.71       611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTaTLXuG1mqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ac3b07-ddc8-4d91-abfb-f95a848d2c56"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_reviews_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.80      0.67        40\n",
            "           1       1.00      0.50      0.67        86\n",
            "           2       0.29      0.76      0.42        17\n",
            "\n",
            "    accuracy                           0.62       143\n",
            "   macro avg       0.62      0.69      0.59       143\n",
            "weighted avg       0.80      0.62      0.64       143\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.72      0.62        40\n",
            "           1       0.89      0.59      0.71        86\n",
            "           2       0.33      0.65      0.44        17\n",
            "\n",
            "    accuracy                           0.64       143\n",
            "   macro avg       0.59      0.66      0.59       143\n",
            "weighted avg       0.73      0.64      0.66       143\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.65      0.64        40\n",
            "           1       0.98      0.52      0.68        86\n",
            "           2       0.25      0.82      0.38        17\n",
            "\n",
            "    accuracy                           0.59       143\n",
            "   macro avg       0.62      0.67      0.57       143\n",
            "weighted avg       0.80      0.59      0.64       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH4tTf4JvIET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb76ea5c-e01f-478e-ed1b-33969cc38e32"
      },
      "source": [
        "majority_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_filmweb_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "<function amin at 0x7fe965122268>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amin at 0x7fe965122268>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.93      0.66        30\n",
            "           1       0.83      0.77      0.80        39\n",
            "           2       0.25      0.07      0.11        30\n",
            "\n",
            "    accuracy                           0.61        99\n",
            "   macro avg       0.53      0.59      0.52        99\n",
            "weighted avg       0.56      0.61      0.55        99\n",
            "\n",
            "<function amax at 0x7fe9651220d0>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function amax at 0x7fe9651220d0>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.90      0.64        30\n",
            "           1       0.71      0.74      0.72        39\n",
            "           2       0.67      0.07      0.12        30\n",
            "\n",
            "    accuracy                           0.59        99\n",
            "   macro avg       0.62      0.57      0.49        99\n",
            "weighted avg       0.63      0.59      0.51        99\n",
            "\n",
            "<function median at 0x7fe964970a60>\n",
            "Making aggregation ...\n",
            "Aggregation finished ...\n",
            "Making final prediciton for tests ...\n",
            "<function median at 0x7fe964970a60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.93      0.67        30\n",
            "           1       0.76      0.82      0.79        39\n",
            "           2       0.50      0.07      0.12        30\n",
            "\n",
            "    accuracy                           0.63        99\n",
            "   macro avg       0.60      0.61      0.53        99\n",
            "weighted avg       0.61      0.63      0.55        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea_p80ITvaOI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def hard_voting_experiment(\n",
        "    test_data_path,\n",
        "    models_paths,\n",
        "    dropnas=True):\n",
        "  \n",
        "  def tensor_dataset(sentences, labels, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                     \n",
        "                            add_special_tokens = True,\n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return dataset\n",
        "\n",
        "  def inverse_logit(x):\n",
        "    return np.exp(x) / (1 + np.exp(x))\n",
        "\n",
        "  def BERT_inference(model, dataloader):\n",
        "    predicted_probs = []; true_labels = []\n",
        "    model.to(device)\n",
        "    for batch in dataloader:\n",
        "      \n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_masks = batch[1].to(device)\n",
        "      labels = batch[2]\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                      \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predicted_probs.extend(inverse_logit(logits))\n",
        "      \n",
        "      labels = labels.numpy().flatten()\n",
        "      true_labels.extend(labels)\n",
        "\n",
        "    return np.array(predicted_probs), np.array(true_labels)\n",
        "\n",
        "  \n",
        "  if torch.cuda.is_available():    \n",
        "\n",
        "      # Tell PyTorch to use the GPU.    \n",
        "      device = torch.device(\"cuda\")\n",
        "\n",
        "      print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  test_data = pd.read_csv(test_data_path, index_col=0)\n",
        "  print(\"Loaded data ...\")\n",
        "  \n",
        "  if dropnas:\n",
        "      test_data = test_data.dropna()\n",
        "      print(\"Dropped NAN's ...\")\n",
        "\n",
        "  tokenizers = []\n",
        "  models = []\n",
        "  for i, model_path in enumerate(models_paths):\n",
        "    print(\"Tokenizer %s model ... \" % i)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "    tokenizers.append(tokenizer)\n",
        "    print(\"%s tokenizer loaded!\" % i)\n",
        "    \n",
        "    print(\"Loading %s model ... \" % i)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    models.append(model)\n",
        "    print(\"%s model loaded!\" % i)\n",
        "\n",
        "  models_test_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    test_dataset = tensor_dataset(test_data.iloc[:,0].to_numpy(), test_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_test_labels = BERT_inference(model, test_dataloader)\n",
        "    models_test_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "\n",
        "  print(\"Started voting ...\")\n",
        "  concatenated_test_data = np.array([np.argmax(model_output,axis=1) for model_output in models_test_output]).T\n",
        "  meta_test_prediction = np.argmax(np.apply_along_axis(np.bincount, axis=1, arr=concatenated_test_data, minlength = np.max(concatenated_test_data) +1), axis=1)\n",
        "  print(\"Voting finished!\")\n",
        "  \n",
        "  print(classification_report(y_true=meta_test_labels, y_pred=meta_test_prediction, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V94DIRzCLyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e3941e-672f-424f-c320-a98e4059b1bd"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_moto_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.73      0.53        79\n",
            "           1       0.75      0.66      0.70       149\n",
            "           2       0.50      0.26      0.35        87\n",
            "\n",
            "    accuracy                           0.57       315\n",
            "   macro avg       0.56      0.55      0.53       315\n",
            "weighted avg       0.60      0.57      0.56       315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLG1kzexCbQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db75b28-27e4-4c1f-ea2d-cb78dffdc6cf"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_treebank_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.69      0.46        32\n",
            "           1       0.26      0.89      0.40        36\n",
            "           2       0.73      0.19      0.30       162\n",
            "\n",
            "    accuracy                           0.37       230\n",
            "   macro avg       0.44      0.59      0.38       230\n",
            "weighted avg       0.60      0.37      0.33       230\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4eo5gfCCjva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a429bc-6380-441a-e3c1-fc0b6de3d51f"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_hotels_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.73      0.82      1033\n",
            "           1       0.88      0.85      0.86       724\n",
            "           2       0.52      0.83      0.64       441\n",
            "\n",
            "    accuracy                           0.79      2198\n",
            "   macro avg       0.78      0.80      0.77      2198\n",
            "weighted avg       0.83      0.79      0.80      2198\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7UwWG-1121A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c05c561-0738-4940-8829-243b672eef3e"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_medicine_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.79      0.76       706\n",
            "           1       0.83      0.69      0.75       518\n",
            "           2       0.76      0.79      0.77       888\n",
            "\n",
            "    accuracy                           0.76      2112\n",
            "   macro avg       0.77      0.76      0.76      2112\n",
            "weighted avg       0.77      0.76      0.76      2112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7OKzBp013EP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c80df4-99a5-45a8-f0f0-686418eeeb07"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_products_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.64      0.75       344\n",
            "           1       0.90      0.69      0.78       194\n",
            "           2       0.26      0.81      0.40        73\n",
            "\n",
            "    accuracy                           0.68       611\n",
            "   macro avg       0.69      0.71      0.64       611\n",
            "weighted avg       0.84      0.68      0.72       611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6n8fhVp13TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4802cc3-c233-46c2-925b-17441a634e83"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_reviews_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.75      0.72        40\n",
            "           1       1.00      0.53      0.70        86\n",
            "           2       0.28      0.88      0.42        17\n",
            "\n",
            "    accuracy                           0.64       143\n",
            "   macro avg       0.66      0.72      0.61       143\n",
            "weighted avg       0.83      0.64      0.67       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMm3gneuCoES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81630eba-9bdf-420a-a218-5847b31fbf08"
      },
      "source": [
        "hard_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_filmweb_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.90      0.68        30\n",
            "           1       0.77      0.85      0.80        39\n",
            "           2       0.50      0.10      0.17        30\n",
            "\n",
            "    accuracy                           0.64        99\n",
            "   macro avg       0.60      0.62      0.55        99\n",
            "weighted avg       0.62      0.64      0.57        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVxu51JYCvJo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def soft_voting_experiment(\n",
        "    test_data_path,\n",
        "    models_paths,\n",
        "    dropnas=True):\n",
        "  \n",
        "  def tensor_dataset(sentences, labels, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                     \n",
        "                            add_special_tokens = True,\n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return dataset\n",
        "\n",
        "  def inverse_logit(x):\n",
        "    return np.exp(x) / (1 + np.exp(x))\n",
        "\n",
        "  def BERT_inference(model, dataloader):\n",
        "    predicted_probs = []; true_labels = []\n",
        "    model.to(device)\n",
        "    for batch in dataloader:\n",
        "      \n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_masks = batch[1].to(device)\n",
        "      labels = batch[2]\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                      \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predicted_probs.extend(inverse_logit(logits))\n",
        "      \n",
        "      labels = labels.numpy().flatten()\n",
        "      true_labels.extend(labels)\n",
        "\n",
        "    return np.array(predicted_probs), np.array(true_labels)\n",
        "\n",
        "  \n",
        "  if torch.cuda.is_available():    \n",
        "\n",
        "      # Tell PyTorch to use the GPU.    \n",
        "      device = torch.device(\"cuda\")\n",
        "\n",
        "      print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  test_data = pd.read_csv(test_data_path, index_col=0)\n",
        "  print(\"Loaded data ...\")\n",
        "  \n",
        "  if dropnas:\n",
        "      test_data = test_data.dropna()\n",
        "      print(\"Dropped NAN's ...\")\n",
        "\n",
        "  tokenizers = []\n",
        "  models = []\n",
        "  for i, model_path in enumerate(models_paths):\n",
        "    print(\"Tokenizer %s model ... \" % i)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "    tokenizers.append(tokenizer)\n",
        "    print(\"%s tokenizer loaded!\" % i)\n",
        "    \n",
        "    print(\"Loading %s model ... \" % i)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    models.append(model)\n",
        "    print(\"%s model loaded!\" % i)\n",
        "\n",
        "  models_test_output = []\n",
        "  for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
        "    print(\"%s data set preparation ...\" % i)\n",
        "    test_dataset = tensor_dataset(test_data.iloc[:,0].to_numpy(), test_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "    test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)\n",
        "    print(\"%s data set preparation end!\" % i)\n",
        "\n",
        "    print(\"%s model inference ...\" % i)\n",
        "    model_output, meta_test_labels = BERT_inference(model, test_dataloader)\n",
        "    models_test_output.append(model_output)\n",
        "    print(\"%s model inference end!\" % i)\n",
        "\n",
        "  print(\"Started voting ...\")\n",
        "  meta_test_prediction = np.argmax(np.sum(np.array(models_test_output), axis=0), axis=1)\n",
        "  print(\"Voting finished!\")\n",
        "  \n",
        "  print(classification_report(y_true=meta_test_labels, y_pred=meta_test_prediction, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rtw28TcGR1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a697158-3958-4c84-a0ee-88f1857c80b8"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_moto_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.72      0.53        79\n",
            "           1       0.75      0.65      0.70       149\n",
            "           2       0.40      0.23      0.29        87\n",
            "\n",
            "    accuracy                           0.55       315\n",
            "   macro avg       0.52      0.53      0.51       315\n",
            "weighted avg       0.57      0.55      0.54       315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF_S41DjGTFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e8e3e1-4535-437a-91a3-3ee5438342e2"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_treebank_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.84      0.52        32\n",
            "           1       0.27      0.92      0.42        36\n",
            "           2       0.86      0.19      0.30       162\n",
            "\n",
            "    accuracy                           0.39       230\n",
            "   macro avg       0.50      0.65      0.41       230\n",
            "weighted avg       0.70      0.39      0.35       230\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OouuzCp9GTap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bcbfc7-c9b4-4afd-88eb-c97a14356db7"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_hotels_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.79      0.86      1033\n",
            "           1       0.89      0.86      0.87       724\n",
            "           2       0.60      0.85      0.70       441\n",
            "\n",
            "    accuracy                           0.83      2198\n",
            "   macro avg       0.81      0.83      0.81      2198\n",
            "weighted avg       0.86      0.83      0.83      2198\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Kqcd5M2KjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf41289-e625-4be2-c066-06ace7716d75"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_medicine_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.85      0.79       706\n",
            "           1       0.85      0.71      0.77       518\n",
            "           2       0.81      0.80      0.80       888\n",
            "\n",
            "    accuracy                           0.79      2112\n",
            "   macro avg       0.80      0.79      0.79      2112\n",
            "weighted avg       0.80      0.79      0.79      2112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DVNWkkR2K1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d9aaa2-2e02-4ef9-c238-b1c501465820"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_products_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.78      0.84       344\n",
            "           1       0.92      0.70      0.79       194\n",
            "           2       0.33      0.77      0.46        73\n",
            "\n",
            "    accuracy                           0.75       611\n",
            "   macro avg       0.72      0.75      0.70       611\n",
            "weighted avg       0.84      0.75      0.78       611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDU_JU8b2LGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d276e0-40eb-491b-9d7c-1cbeeafb247f"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_reviews_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.72      0.69        40\n",
            "           1       0.98      0.55      0.70        86\n",
            "           2       0.29      0.88      0.44        17\n",
            "\n",
            "    accuracy                           0.64       143\n",
            "   macro avg       0.64      0.72      0.61       143\n",
            "weighted avg       0.81      0.64      0.67       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlskZwAdGTub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5252e379-25da-4ba0-cc36-19ca6244d490"
      },
      "source": [
        "soft_voting_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_filmweb_data_preprocessed.csv',\n",
        "    models_paths = [\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_1\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_1_4\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_2\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_3\",\n",
        "                    \"/content/drive/My Drive/model_bert_finetuned_4\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer 0 model ... \n",
            "0 tokenizer loaded!\n",
            "Loading 0 model ... \n",
            "0 model loaded!\n",
            "Tokenizer 1 model ... \n",
            "1 tokenizer loaded!\n",
            "Loading 1 model ... \n",
            "1 model loaded!\n",
            "Tokenizer 2 model ... \n",
            "2 tokenizer loaded!\n",
            "Loading 2 model ... \n",
            "2 model loaded!\n",
            "Tokenizer 3 model ... \n",
            "3 tokenizer loaded!\n",
            "Loading 3 model ... \n",
            "3 model loaded!\n",
            "Tokenizer 4 model ... \n",
            "4 tokenizer loaded!\n",
            "Loading 4 model ... \n",
            "4 model loaded!\n",
            "Tokenizer 5 model ... \n",
            "5 tokenizer loaded!\n",
            "Loading 5 model ... \n",
            "5 model loaded!\n",
            "Tokenizer 6 model ... \n",
            "6 tokenizer loaded!\n",
            "Loading 6 model ... \n",
            "6 model loaded!\n",
            "0 data set preparation ...\n",
            "0 data set preparation end!\n",
            "0 model inference ...\n",
            "0 model inference end!\n",
            "1 data set preparation ...\n",
            "1 data set preparation end!\n",
            "1 model inference ...\n",
            "1 model inference end!\n",
            "2 data set preparation ...\n",
            "2 data set preparation end!\n",
            "2 model inference ...\n",
            "2 model inference end!\n",
            "3 data set preparation ...\n",
            "3 data set preparation end!\n",
            "3 model inference ...\n",
            "3 model inference end!\n",
            "4 data set preparation ...\n",
            "4 data set preparation end!\n",
            "4 model inference ...\n",
            "4 model inference end!\n",
            "5 data set preparation ...\n",
            "5 data set preparation end!\n",
            "5 model inference ...\n",
            "5 model inference end!\n",
            "6 data set preparation ...\n",
            "6 data set preparation end!\n",
            "6 model inference ...\n",
            "6 model inference end!\n",
            "Started voting ...\n",
            "Voting finished!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.93      0.68        30\n",
            "           1       0.77      0.85      0.80        39\n",
            "           2       0.50      0.07      0.12        30\n",
            "\n",
            "    accuracy                           0.64        99\n",
            "   macro avg       0.60      0.62      0.54        99\n",
            "weighted avg       0.62      0.64      0.56        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YQyQZUOL-hB"
      },
      "source": [
        "**Baselines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAom_CMfGhgb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def baseline_experiment(\n",
        "    test_data_path,\n",
        "    model_path,\n",
        "    dropnas=True):\n",
        "  \n",
        "  def tensor_dataset(sentences, labels, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                     \n",
        "                            add_special_tokens = True,\n",
        "                            max_length = MAX_LEN,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return dataset\n",
        "  \n",
        "  def BERT_inference(model, dataloader):\n",
        "    predicted_labels = []; true_labels = []\n",
        "    model.to(device)\n",
        "    for batch in dataloader:\n",
        "      \n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_masks = batch[1].to(device)\n",
        "      labels = batch[2]\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                      \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "\n",
        "      predictions = np.argmax(logits, axis=1).flatten()\n",
        "      labels = labels.numpy().flatten()\n",
        "\n",
        "      predicted_labels.extend(predictions)\n",
        "      true_labels.extend(labels)\n",
        "\n",
        "    return np.array(predicted_labels), np.array(true_labels)\n",
        "\n",
        "  \n",
        "  if torch.cuda.is_available():    \n",
        "\n",
        "      # Tell PyTorch to use the GPU.    \n",
        "      device = torch.device(\"cuda\")\n",
        "\n",
        "      print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  test_data = pd.read_csv(test_data_path, index_col=0)\n",
        "  print(\"Loaded data ...\")\n",
        "\n",
        "  if dropnas:\n",
        "      test_data = test_data.dropna()\n",
        "      print(\"Dropped NAN's ...\")\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "  print(\"Tokenizer loaded!\")\n",
        "  \n",
        "  model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "  print(\"Model loaded!\")\n",
        "\n",
        "  print(\"Data set preparation ...\")\n",
        "  test_dataset = tensor_dataset(test_data.iloc[:,0].to_numpy(), test_data.iloc[:,1].to_numpy(), tokenizer)\n",
        "  test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)\n",
        "  print(\"Data set preparation end!\")\n",
        "\n",
        "  print(\"Model inference ...\")\n",
        "  model_output, test_labels = BERT_inference(model, test_dataloader)\n",
        "  print(\"Model inference end!\")\n",
        "  \n",
        "  print(classification_report(y_true=test_labels, y_pred=model_output, zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQLhi9ndNGGs",
        "outputId": "dc6d7c23-b254-4841-f2a2-7c330046c770"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_moto_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_2\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.62      0.66        79\n",
            "           1       0.83      0.83      0.83       149\n",
            "           2       0.57      0.63      0.60        87\n",
            "\n",
            "    accuracy                           0.72       315\n",
            "   macro avg       0.70      0.69      0.70       315\n",
            "weighted avg       0.73      0.72      0.72       315\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1gtnjOeNreU",
        "outputId": "e1b9e5f7-82a0-4f6c-c8b6-74ec93100d20"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path =  '/content/drive/My Drive/test_treebank_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_4\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.47        32\n",
            "           1       0.59      0.61      0.60        36\n",
            "           2       0.81      0.85      0.83       162\n",
            "\n",
            "    accuracy                           0.75       230\n",
            "   macro avg       0.66      0.62      0.63       230\n",
            "weighted avg       0.74      0.75      0.74       230\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQxWlqznOpKp",
        "outputId": "4a0cc041-1f93-487d-a4a8-3a88d8b0569f"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_hotels_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_1_1\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92      1033\n",
            "           1       0.91      0.92      0.91       724\n",
            "           2       0.84      0.77      0.80       441\n",
            "\n",
            "    accuracy                           0.90      2198\n",
            "   macro avg       0.89      0.87      0.88      2198\n",
            "weighted avg       0.89      0.90      0.89      2198\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9UZ6guuOpmb",
        "outputId": "0aeb788f-3fee-45c1-bd5d-061f7dd0c6ea"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_medicine_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_1_2\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       706\n",
            "           1       0.82      0.82      0.82       518\n",
            "           2       0.84      0.86      0.85       888\n",
            "\n",
            "    accuracy                           0.83      2112\n",
            "   macro avg       0.83      0.83      0.83      2112\n",
            "weighted avg       0.83      0.83      0.83      2112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0RN2cC5OqJM",
        "outputId": "c4734176-724d-4f77-e233-c16d4f653dd0"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_products_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_1_3\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90       344\n",
            "           1       0.89      0.85      0.87       194\n",
            "           2       0.66      0.53      0.59        73\n",
            "\n",
            "    accuracy                           0.85       611\n",
            "   macro avg       0.81      0.77      0.78       611\n",
            "weighted avg       0.85      0.85      0.85       611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK7S6KZHOrti",
        "outputId": "a4411c12-c1ec-4be4-d468-0614ab2a3c36"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_polemo_reviews_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_1_4\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.75      0.73        40\n",
            "           1       0.84      0.81      0.83        86\n",
            "           2       0.50      0.53      0.51        17\n",
            "\n",
            "    accuracy                           0.76       143\n",
            "   macro avg       0.69      0.70      0.69       143\n",
            "weighted avg       0.77      0.76      0.76       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baiXrhIfOrk3",
        "outputId": "56c37ddf-9beb-4ac6-e2a9-6c74475fba49"
      },
      "source": [
        "baseline_experiment(\n",
        "    test_data_path = '/content/drive/My Drive/test_filmweb_data_preprocessed.csv',\n",
        "    model_path = \"/content/drive/My Drive/model_bert_finetuned_3\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Loaded data ...\n",
            "Dropped NAN's ...\n",
            "Tokenizer loaded!\n",
            "Model loaded!\n",
            "Data set preparation ...\n",
            "Data set preparation end!\n",
            "Model inference ...\n",
            "Model inference end!\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.83      0.72        30\n",
            "           1       0.89      0.85      0.87        39\n",
            "           2       0.70      0.53      0.60        30\n",
            "\n",
            "    accuracy                           0.75        99\n",
            "   macro avg       0.74      0.74      0.73        99\n",
            "weighted avg       0.76      0.75      0.74        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDY9B2MIPljK"
      },
      "source": [
        "# Accuracy\n",
        "baseline_moto = 0.72\n",
        "baseline_tw = 0.75\n",
        "baseline_polemo_hotels = 0.9\n",
        "baseline_polemo_medicine = 0.83\n",
        "baseline_polemo_products = 0.85\n",
        "baseline_polemo_reviews = 0.76\n",
        "baseline_films = 0.75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv4tE7unpcf-"
      },
      "source": [
        "# Accuracy\n",
        "metaSVM_moto = 0.7\n",
        "metaSVM_tw = 0.71\n",
        "metaSVM_polemo_hotels = 0.89\n",
        "metaSVM_polemo_medicine = 0.83\n",
        "metaSVM_polemo_products = 0.86\n",
        "metaSVM_polemo_reviews = 0.77\n",
        "metaSVM_films = 0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaT9ma3CrgKQ"
      },
      "source": [
        "# Accuracy\n",
        "metaxgboost_moto = 0.71\n",
        "metaxgboost_tw = 0.72\n",
        "metaxgboost_polemo_hotels = 0.89\n",
        "metaxgboost_polemo_medicine = 0.84\n",
        "metaxgboost_polemo_products = 0.86\n",
        "metaxgboost_polemo_reviews = 0.78\n",
        "metaxgboost_films = 0.68"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eugNLnOnrx-W"
      },
      "source": [
        "# Accuracy\n",
        "min_moto, max_moto, median_moto = 0.46, 0.49, 0.56\n",
        "min_tw, max_tw, median_tw = 0.38, 0.39, 0.4\n",
        "min_polemo_hotels, max_polemo_hotels, median_polemo_hotels = 0.85, 0.86, 0.79\n",
        "min_polemo_medicine, max_polemo_medicine, median_polemo_medicine = 0.79, 0.81, 0.77\n",
        "min_polemo_products, max_polemo_products, median_polemo_products = 0.76, 0.70, 0.66\n",
        "min_polemo_reviews, max_polemo_reviews, median_polemo_reviews = 0.62, 0.64, 0.59\n",
        "min_films, max_films, median_films = 0.61, 0.59, 0.63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltgAK3gfsrQG"
      },
      "source": [
        "# Accuracy\n",
        "hard_vote_moto = 0.57\n",
        "hard_vote_tw = 0.37\n",
        "hard_vote_polemo_hotels = 0.79\n",
        "hard_vote_polemo_medicine = 0.76\n",
        "hard_vote_polemo_products = 0.68\n",
        "hard_vote_polemo_reviews = 0.64\n",
        "hard_vote_films = 0.64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di_b9TMOsxyu"
      },
      "source": [
        "# Accuracy\n",
        "soft_vote_moto = 0.55\n",
        "soft_vote_tw = 0.39\n",
        "soft_vote_polemo_hotels = 0.83\n",
        "soft_vote_polemo_medicine = 0.79\n",
        "soft_vote_polemo_products = 0.75\n",
        "soft_vote_polemo_reviews = 0.64\n",
        "soft_vote_films = 0.64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUCa4GHk6HYo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "2UhPffwxteKb",
        "outputId": "98327a01-5325-4407-fca8-1c760eccb532"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "font = {'weight' : 'bold',\n",
        "        'size'   : 14}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "labels = ['Motofakty', 'TW', 'PolEmo Hotels', 'PolEmo Medicine', 'PolEmo Products', 'PolEmo Reviews', 'Films']\n",
        "baseline = [\n",
        "        baseline_moto,\n",
        "        baseline_tw,\n",
        "        baseline_polemo_hotels,\n",
        "        baseline_polemo_medicine,\n",
        "        baseline_polemo_products,\n",
        "        baseline_polemo_reviews,\n",
        "        baseline_films \n",
        "]\n",
        "metaSVM = [\n",
        "          metaSVM_moto,\n",
        "          metaSVM_tw,\n",
        "          metaSVM_polemo_hotels,\n",
        "          metaSVM_polemo_medicine,\n",
        "          metaSVM_polemo_products,\n",
        "          metaSVM_polemo_reviews,\n",
        "          metaSVM_films\n",
        "]\n",
        "metaxgboost = [\n",
        "              metaxgboost_moto,\n",
        "              metaxgboost_tw,\n",
        "              metaxgboost_polemo_hotels,\n",
        "              metaxgboost_polemo_medicine,\n",
        "              metaxgboost_polemo_products,\n",
        "              metaxgboost_polemo_reviews,\n",
        "              metaxgboost_films\n",
        "]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.3  # the width of the bars\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "plt.ylim(ymax = 0.95, ymin = 0.65)\n",
        "rects1 = ax.bar(x - width, baseline, width, label='Baseline')\n",
        "rects2 = ax.bar(x, metaSVM, width, label='SVM ML')\n",
        "rects3 = ax.bar(x + width, metaxgboost, width, label='XGBoost ML')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Scores by data set and method')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "cprnlJtu7F07",
        "outputId": "86664f93-98d6-4ebd-8e27-89271520e0da"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "font = {'weight' : 'bold',\n",
        "        'size'   : 14}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "labels = [\n",
        "          'Motofakty', 'TW', \n",
        "          #'PolEmo Hotels', 'PolEmo Medicine', 'PolEmo Products', 'PolEmo Reviews', \n",
        "          'Films'\n",
        "          ]\n",
        "baseline = [\n",
        "        baseline_moto,\n",
        "        baseline_tw,\n",
        "        #baseline_polemo_hotels,\n",
        "        #baseline_polemo_medicine,\n",
        "        #baseline_polemo_products,\n",
        "        #baseline_polemo_reviews,\n",
        "        baseline_films \n",
        "]\n",
        "min = [\n",
        "      #min_moto, \n",
        "      #min_tw, \n",
        "      min_polemo_hotels, \n",
        "      min_polemo_medicine,\n",
        "      min_polemo_products, \n",
        "      min_polemo_reviews, \n",
        "      #min_films\n",
        "]\n",
        "max = [\n",
        "      #max_moto,\n",
        "      #max_tw,\n",
        "      max_polemo_hotels,\n",
        "      max_polemo_medicine,\n",
        "      max_polemo_products,\n",
        "      max_polemo_reviews,\n",
        "      #max_films\n",
        "]\n",
        "median = [\n",
        "        #median_moto,\n",
        "        #median_tw,\n",
        "        median_polemo_hotels, \n",
        "        median_polemo_medicine,\n",
        "        median_polemo_products,\n",
        "        median_polemo_reviews,\n",
        "        #median_films \n",
        "]\n",
        "hard_vote = [\n",
        "            hard_vote_moto,\n",
        "            hard_vote_tw,\n",
        "            #hard_vote_polemo_hotels,\n",
        "            #hard_vote_polemo_medicine,\n",
        "            #hard_vote_polemo_products,\n",
        "            #hard_vote_polemo_reviews,\n",
        "            hard_vote_films\n",
        "]\n",
        "soft_vote = [\n",
        "            soft_vote_moto,\n",
        "            soft_vote_tw,\n",
        "            #soft_vote_polemo_hotels,\n",
        "            #soft_vote_polemo_medicine,\n",
        "            #soft_vote_polemo_products,\n",
        "            #soft_vote_polemo_reviews,\n",
        "            soft_vote_films\n",
        "]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "plt.ylim(ymax = 0.95, ymin = 0.35)\n",
        "rects1 = ax.bar(x - width, baseline, width, label='Baseline')\n",
        "rects2 = ax.bar(x, hard_vote, width, label='Hard voting')\n",
        "rects3 = ax.bar(x + width, soft_vote, width, label='Soft voting')\n",
        "#rects4 = ax.bar(x + 1.5*width, median, width, label='Median aggregation')\n",
        "#rects5 = ax.bar(x + 1.5*width, hard_vote, width, label='Hard voting')\n",
        "#rects6 = ax.bar(x + 3*width, soft_vote, width, label='Soft voting')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Scores by data set and method')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "#autolabel(rects4)\n",
        "#autolabel(rects5)\n",
        "#autolabel(rects6)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNjhNIPGyDnt"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def bar_plot(ax, data, colors=None, total_width=0.8, single_width=1, legend=True, labels=None):\n",
        "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ax : matplotlib.pyplot.axis\n",
        "        The axis we want to draw our plot on.\n",
        "\n",
        "    data: dictionary\n",
        "        A dictionary containing the data we want to plot. Keys are the names of the\n",
        "        data, the items is a list of the values.\n",
        "\n",
        "        Example:\n",
        "        data = {\n",
        "            \"x\":[1,2,3],\n",
        "            \"y\":[1,2,3],\n",
        "            \"z\":[1,2,3],\n",
        "        }\n",
        "\n",
        "    colors : array-like, optional\n",
        "        A list of colors which are used for the bars. If None, the colors\n",
        "        will be the standard matplotlib color cyle. (default: None)\n",
        "\n",
        "    total_width : float, optional, default: 0.8\n",
        "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
        "        by bars and 20% will be spaces between the bars.\n",
        "\n",
        "    single_width: float, optional, default: 1\n",
        "        The relative width of a single bar within a group. 1 means the bars\n",
        "        will touch eachother within a group, values less than 1 will make\n",
        "        these bars thinner.\n",
        "\n",
        "    legend: bool, optional, default: True\n",
        "        If this is set to true, a legend will be added to the axis.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if colors where provided, otherwhise use the default color cycle\n",
        "    if colors is None:\n",
        "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "    # Number of bars per group\n",
        "    n_bars = len(data)\n",
        "\n",
        "    # The width of a single bar\n",
        "    bar_width = total_width / n_bars\n",
        "\n",
        "    # List containing handles for the drawn bars, used for the legend\n",
        "    bars = []\n",
        "\n",
        "    # Iterate over all data\n",
        "    for i, (name, values) in enumerate(data.items()):\n",
        "        # The offset in x direction of that bar\n",
        "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
        "\n",
        "        # Draw a bar for every value of that type\n",
        "        for x, y in enumerate(values):\n",
        "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
        "\n",
        "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
        "        bars.append(bar[0])\n",
        "        \n",
        "    # Draw legend if we need\n",
        "    if legend:\n",
        "        ax.legend(bars, data.keys())\n",
        "        ax.set_xticklabels(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv9_M3hT0uNO"
      },
      "source": [
        "baseline = [\n",
        "        baseline_moto,\n",
        "        baseline_tw,\n",
        "        baseline_polemo_hotels,\n",
        "        baseline_polemo_medicine,\n",
        "        baseline_polemo_products,\n",
        "        baseline_polemo_reviews,\n",
        "        baseline_films \n",
        "]\n",
        "metaSVM = [\n",
        "          metaSVM_moto,\n",
        "          metaSVM_tw,\n",
        "          metaSVM_polemo_hotels,\n",
        "          metaSVM_polemo_medicine,\n",
        "          metaSVM_polemo_products,\n",
        "          metaSVM_polemo_reviews,\n",
        "          metaSVM_films\n",
        "]\n",
        "metaxgboost = [\n",
        "              metaxgboost_moto,\n",
        "              metaxgboost_tw,\n",
        "              metaxgboost_polemo_hotels,\n",
        "              metaxgboost_polemo_medicine,\n",
        "              metaxgboost_polemo_products,\n",
        "              metaxgboost_polemo_reviews,\n",
        "              metaxgboost_films\n",
        "]\n",
        "min = [\n",
        "      min_moto, \n",
        "      min_tw, \n",
        "      min_polemo_hotels, \n",
        "      min_medicine,\n",
        "      min_products, \n",
        "      min_reviews, \n",
        "      min_films\n",
        "]\n",
        "max = [\n",
        "      max_moto,\n",
        "      max_tw,\n",
        "      max_polemo_hotels,\n",
        "      max_medicine,\n",
        "      max_products,\n",
        "      max_reviews,\n",
        "      max_films\n",
        "]\n",
        "median = [\n",
        "        median_moto,\n",
        "        median_tw,\n",
        "        median_polemo_hotels, \n",
        "        median_medicine,\n",
        "        median_products,\n",
        "        median_reviews,\n",
        "        median_films \n",
        "]\n",
        "hard_vote = [\n",
        "            hard_vote_moto,\n",
        "            hard_vote_tw,\n",
        "            hard_vote_polemo_hotels,\n",
        "            hard_vote_polemo_medicine,\n",
        "            hard_vote_polemo_products,\n",
        "            hard_vote_polemo_reviews,\n",
        "            hard_vote_films\n",
        "]\n",
        "soft_vote = [\n",
        "            soft_vote_moto,\n",
        "            soft_vote_tw,\n",
        "            soft_vote_polemo_hotels,\n",
        "            soft_vote_polemo_medicine,\n",
        "            soft_vote_polemo_products,\n",
        "            soft_vote_polemo_reviews,\n",
        "            soft_vote_films\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cJ_sAEW1GqW"
      },
      "source": [
        "labels = ['Motofakty', 'TW', 'PolEmo Hotels', 'PolEmo Medicine', 'PolEmo Products', 'PolEmo Reviews', 'Films']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "ekm8QrRlyFAn",
        "outputId": "94dce0f4-bb91-4b4f-9684-bd7eefaf073e"
      },
      "source": [
        "data = {\n",
        "        'Baseline': baseline, \n",
        "        'SVM ML': metaSVM,\n",
        "        'XGBoost ML': metaxgboost,\n",
        "        #'Min aggregation': min,\n",
        "        #'Max aggregation': max,\n",
        "        #'Median aggregation': median,\n",
        "        #'Hard voting': hard_vote,\n",
        "        #'Soft voting': soft_vote\n",
        "    }\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "plt.ylim(ymax = 0.95, ymin = 0.65)\n",
        "bar_plot(ax, data, total_width=.8, single_width=.9, labels = labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yphhofu23yoM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "motofakty_base_classifiers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "labYOW08KLe1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq_LWw01KSfo"
      },
      "source": [
        "dirty_data = pd.read_csv('/content/opinie.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oZcYhckLKRs"
      },
      "source": [
        "def rescale_rank(rank: int):\n",
        "  if rank > 3:\n",
        "    return 1\n",
        "  elif rank < 3:\n",
        "    return 0\n",
        "  else:\n",
        "    return 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VviG97PfK0b7"
      },
      "source": [
        "dirty_data['ocena'] = dirty_data['ocena'].apply(lambda x: rescale_rank(int(x[7])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn3DsOfSMhAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f0227a71-f48c-471a-bb0b-562f14e0a710"
      },
      "source": [
        "dirty_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>strona</th>\n",
              "      <th>opinia</th>\n",
              "      <th>ocena</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/aeon...</td>\n",
              "      <td>Lpl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/acur...</td>\n",
              "      <td>MA SWOJE LATA (2006) ALE OK.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/acur...</td>\n",
              "      <td>NO KUPIŁBYM ZADBANEGO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/aust...</td>\n",
              "      <td>Polecam super klasyk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/abar...</td>\n",
              "      <td>samochód ładny,bezpieczny,szybki.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              strona  ... ocena\n",
              "0  https://www.motofakty.pl/samochody/opinie/aeon...  ...     0\n",
              "1  https://www.motofakty.pl/samochody/opinie/acur...  ...     1\n",
              "2  https://www.motofakty.pl/samochody/opinie/acur...  ...     1\n",
              "3  https://www.motofakty.pl/samochody/opinie/aust...  ...     1\n",
              "4  https://www.motofakty.pl/samochody/opinie/abar...  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAp-W6lMkHbg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7d9c1a49-74fc-4655-f55e-0bea55cd54c4"
      },
      "source": [
        "dirty_data.ocena.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    35975\n",
              "2      899\n",
              "0      803\n",
              "Name: ocena, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te5N-Q3Nle_c"
      },
      "source": [
        "non_positive = dirty_data.loc[dirty_data.ocena != 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOz2526_khnw"
      },
      "source": [
        "positive = dirty_data.loc[dirty_data.ocena == 1].sample(1500, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-wjZkkTlvsY"
      },
      "source": [
        "moto_data = positive.append(non_positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBj_4qsGLcM"
      },
      "source": [
        "with open('/content/stopwords.txt', \"r\") as f:\n",
        "  STOP_WORDS = set([line.rstrip(\"\\n\") for line in f])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPBnTRDFEUx6"
      },
      "source": [
        "def preprocess(intext: str):\n",
        "  text = re.sub(r'\\W+', ' ', intext.lower()).split()\n",
        "  text = \" \".join([word for word in text if word not in STOP_WORDS])\n",
        "\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cov2R6u2Gu8f"
      },
      "source": [
        "moto_data['opinia'] = moto_data['opinia'].apply(lambda x: preprocess(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m0npcqpmj4D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b5dba8fe-4f88-4ccc-cf93-c4dcabdadfe8"
      },
      "source": [
        "moto_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>strona</th>\n",
              "      <th>opinia</th>\n",
              "      <th>ocena</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32387</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/toyo...</td>\n",
              "      <td>auto zadba ipodokreca morzna cieszyc przyjemno...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3163</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/bmw/...</td>\n",
              "      <td>bmw b 12 750 spalanie miasto 19l 100 100 km h ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16910</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/mazd...</td>\n",
              "      <td>wdzieczny pojazd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14056</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/isuz...</td>\n",
              "      <td>całkiem dobry samochód mogę polecić jedynie po...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19701</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/niss...</td>\n",
              "      <td>kupił bym ponownie auto</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  strona  ... ocena\n",
              "32387  https://www.motofakty.pl/samochody/opinie/toyo...  ...     1\n",
              "3163   https://www.motofakty.pl/samochody/opinie/bmw/...  ...     1\n",
              "16910  https://www.motofakty.pl/samochody/opinie/mazd...  ...     1\n",
              "14056  https://www.motofakty.pl/samochody/opinie/isuz...  ...     1\n",
              "19701  https://www.motofakty.pl/samochody/opinie/niss...  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEeBsMbmA66E"
      },
      "source": [
        "moto_data.to_csv('/content/drive/My Drive/moto_data_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzG8Ur4ds6FC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91278232-ad19-4116-842c-3a9f25c5f123"
      },
      "source": [
        "!pip install transformers==2.8.0 -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 573kB 13.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 47.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 56.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.9MB 52.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: botocore 1.19.25 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5X6rFYbs9IG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrjLU-FHs_pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f5e96d-d25f-4778-91f9-2fdbc9804aa2"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "#model.cuda()\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCxzr8ZWoelM"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "moto_data = pd.read_csv('/content/drive/My Drive/moto_data_preprocessed.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoG_JM5jxFu6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "be28e81b-c6e0-4e33-9584-267c301e1358"
      },
      "source": [
        "moto_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>strona</th>\n",
              "      <th>opinia</th>\n",
              "      <th>ocena</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32387</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/toyo...</td>\n",
              "      <td>auto zadba ipodokreca morzna cieszyc przyjemno...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3163</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/bmw/...</td>\n",
              "      <td>bmw b 12 750 spalanie miasto 19l 100 100 km h ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16910</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/mazd...</td>\n",
              "      <td>wdzieczny pojazd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14056</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/isuz...</td>\n",
              "      <td>całkiem dobry samochód mogę polecić jedynie po...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19701</th>\n",
              "      <td>https://www.motofakty.pl/samochody/opinie/niss...</td>\n",
              "      <td>kupił bym ponownie auto</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  strona  ... ocena\n",
              "32387  https://www.motofakty.pl/samochody/opinie/toyo...  ...     1\n",
              "3163   https://www.motofakty.pl/samochody/opinie/bmw/...  ...     1\n",
              "16910  https://www.motofakty.pl/samochody/opinie/mazd...  ...     1\n",
              "14056  https://www.motofakty.pl/samochody/opinie/isuz...  ...     1\n",
              "19701  https://www.motofakty.pl/samochody/opinie/niss...  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lItFoDB7GVau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19117a1-beef-4f96-cd37-4d55f3af72d6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.max(moto_data.opinia.str.split().map(len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WCdEazBGPOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b044472c-7679-4bdb-cbea-a6787b043fd4"
      },
      "source": [
        "moto_data.ocena.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1500\n",
              "2     899\n",
              "0     803\n",
              "Name: ocena, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj3molJKq6HT"
      },
      "source": [
        "moto_data.opinia = moto_data.opinia.astype(str)\n",
        "moto_data.ocena = moto_data.ocena.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJbYYIH7xPO0"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "X = moto_data.opinia.to_numpy()\n",
        "y = moto_data.ocena.to_numpy()\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  train_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  train_labels, test_labels = y[train_index], y[test_index]\n",
        "\n",
        "X = test_sentences\n",
        "y = test_labels\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.33, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  dev_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  dev_labels, test_labels = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-idXdj_XxgPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0805c72d-d3b2-4aaa-dfe2-1f814aeee12b"
      },
      "source": [
        "print('Train data')\n",
        "print(len(train_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Dev data')\n",
        "print(len(dev_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Test data')\n",
        "print(len(test_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data\n",
            "0.6998750780762024\n",
            "Dev data\n",
            "0.20081199250468457\n",
            "Test data\n",
            "0.09931292941911306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJvnNbIlwY6J"
      },
      "source": [
        "dev_moto_data = pd.DataFrame([dev_sentences,dev_labels]).T\n",
        "test_moto_data = pd.DataFrame([test_sentences,test_labels]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DElp6wU9w4Aq"
      },
      "source": [
        "dev_moto_data.to_csv('/content/drive/My Drive/dev_moto_data_preprocessed.csv')\n",
        "test_moto_data.to_csv('/content/drive/My Drive/test_moto_data_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iFaNga-xz4L"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "X = train_sentences\n",
        "y = train_labels\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  train_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  train_labels, test_labels = y[train_index], y[test_index]\n",
        "\n",
        "X = test_sentences\n",
        "y = test_labels\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  dev_sentences, test_sentences = X[train_index], X[test_index]\n",
        "  dev_labels, test_labels = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i5_3kANyDmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26059bf-687c-401c-cdc8-78259facf2ef"
      },
      "source": [
        "print('Train data')\n",
        "print(len(train_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Dev data')\n",
        "print(len(dev_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))\n",
        "print('Test data')\n",
        "print(len(test_sentences) / ( len(train_sentences) + len(dev_sentences) + len(test_sentences) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data\n",
            "0.7996430165104864\n",
            "Dev data\n",
            "0.0999553770638108\n",
            "Test data\n",
            "0.10040160642570281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqwTHObYyFdu"
      },
      "source": [
        "# Remove long sentences.\n",
        "# TO-DO Possible cut?\n",
        "def remove_big(sentences, labels):\n",
        "  to_remove = []\n",
        "  for i, sent in enumerate(sentences):\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True) # TO-DO: add_special_tokens\n",
        "      if len(input_ids) > MAX_LEN:\n",
        "        to_remove.append(i)\n",
        "\n",
        "  sentences = np.delete(sentences, to_remove)\n",
        "  labels = np.delete(labels, to_remove) \n",
        "\n",
        "  print('{} samples removed.'.format(len(to_remove)))\n",
        "\n",
        "  return sentences, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a37vHjlPzPX1"
      },
      "source": [
        "# Downloading tokenizer\n",
        "# From Polbert - Polish BERT by Darek Kłeczek: https://github.com/kldarek/polbert\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzgAP2e2qxRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd258b10-0995-4fca-c5b2-fa58767aef22"
      },
      "source": [
        "train_sentences.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BecTDvMmzTBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e99452e-23d2-42be-a076-95659532c3c7"
      },
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "train_sentences, train_labels = remove_big(train_sentences, train_labels)\n",
        "test_sentences, test_labels = remove_big(test_sentences, test_labels)\n",
        "dev_sentences, dev_labels = remove_big(dev_sentences, dev_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51 samples removed.\n",
            "9 samples removed.\n",
            "7 samples removed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjG_LNENzWOY"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "# Create TensorDatasets for train/dev/test sets\n",
        "def tensor_dataset(sentences, labels):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  for sent in sentences:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                     \n",
        "                          add_special_tokens = True,\n",
        "                          max_length = MAX_LEN,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazDSA-ZzZbq"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataset = tensor_dataset(train_sentences, train_labels)\n",
        "test_dataset = tensor_dataset(test_sentences, test_labels)\n",
        "dev_dataset = tensor_dataset(dev_sentences, dev_labels)\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "# Create the DataLoaders for train/dev/test sets.\n",
        "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = BATCH_SIZE)\n",
        "validation_dataloader = DataLoader(dev_dataset, sampler = SequentialSampler(dev_dataset), batch_size = BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXAJU6Lhzf8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609a494d-c44e-4dc4-a13f-79ebfc6f30c7"
      },
      "source": [
        "# Load model with a sequence classification head\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dkleczek/bert-base-polish-uncased-v1\", # Polbert - Polish BERT by Darek Kłeczek: https://github.com/kldarek/polbert\n",
        "    num_labels = 3,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(60000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i13lrjYzi4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef91ae7-d5a5-4f6b-ecdb-3f488d827dc1"
      },
      "source": [
        "import time, datetime\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.optimization import AdamW\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Takes a time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round((elapsed)))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# Parameters:\n",
        "epochs = 3\n",
        "#lr = 1e-3 # Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "lr = 5e-5 # Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "adam_epsilon = 1e-10\n",
        "WARM_UP = 0\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = lr, eps = adam_epsilon)\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = WARM_UP, num_training_steps = total_steps)\n",
        "\n",
        "train_loss_values = []\n",
        "dev_acc_values = []\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch_i in range(0, epochs):  \n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  # https://github.com/huggingface/transformers/blob/master/examples/run_glue.py\n",
        "  # linie 168-183\n",
        "  epoch_train_loss = 0 # Cumulative loss\n",
        "  loss = 0 ;     batch_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)      \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}. Loss: {:.3f}  Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "    \n",
        "\n",
        "    batch_loss = 0\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)    \n",
        "\n",
        "    # clear any previously calculated gradients before backward pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "    epoch_train_loss += loss.item()\n",
        "    batch_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n",
        "    optimizer.step()\n",
        "    scheduler.step()  # Update learning rate schedule\n",
        "\n",
        "  epoch_train_loss = epoch_train_loss / len(train_dataloader)          \n",
        "  train_loss_values.append(epoch_train_loss)\n",
        "  \n",
        "  print('Average training loss: {0:.2f}'.format(epoch_train_loss))\n",
        "\n",
        "  # Evaluation\n",
        "  total_eval_accuracy = 0\n",
        "  model.eval()\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    \n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_masks = batch[1].to(device)\n",
        "    labels = batch[2].to('cpu').numpy()\n",
        "                \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    predictions = np.argmax(logits, axis=1).flatten()\n",
        "    total_eval_accuracy += flat_accuracy(logits, labels)\n",
        "\n",
        "  avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "  print(\"  Accuracy: {0:.4f}\".format(avg_val_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of    218. Loss: 0.808  Elapsed: 0:00:08.\n",
            "  Batch    80  of    218. Loss: 1.689  Elapsed: 0:00:17.\n",
            "  Batch   120  of    218. Loss: 0.841  Elapsed: 0:00:25.\n",
            "  Batch   160  of    218. Loss: 1.253  Elapsed: 0:00:34.\n",
            "  Batch   200  of    218. Loss: 0.574  Elapsed: 0:00:43.\n",
            "Average training loss: 0.95\n",
            "  Accuracy: 0.6518\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    218. Loss: 0.243  Elapsed: 0:00:57.\n",
            "  Batch    80  of    218. Loss: 0.387  Elapsed: 0:01:05.\n",
            "  Batch   120  of    218. Loss: 1.098  Elapsed: 0:01:14.\n",
            "  Batch   160  of    218. Loss: 0.506  Elapsed: 0:01:23.\n",
            "  Batch   200  of    218. Loss: 1.042  Elapsed: 0:01:32.\n",
            "Average training loss: 0.63\n",
            "  Accuracy: 0.5982\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    218. Loss: 0.759  Elapsed: 0:01:46.\n",
            "  Batch    80  of    218. Loss: 0.196  Elapsed: 0:01:55.\n",
            "  Batch   120  of    218. Loss: 0.113  Elapsed: 0:02:04.\n",
            "  Batch   160  of    218. Loss: 0.321  Elapsed: 0:02:13.\n",
            "  Batch   200  of    218. Loss: 0.373  Elapsed: 0:02:21.\n",
            "Average training loss: 0.34\n",
            "  Accuracy: 0.6518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEOpWVegzn52"
      },
      "source": [
        "predicted_labels = [] ; true_labels = []; logits_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "  \n",
        "  input_ids = batch[0].to(device)\n",
        "  attention_masks = batch[1].to(device)\n",
        "  labels = batch[2]\n",
        "  \n",
        "  with torch.no_grad():        \n",
        "      outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "                  \n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  logits_list.append(logits)\n",
        "  \n",
        "  predictions = np.argmax(logits, axis=1).flatten()\n",
        "  labels = labels.numpy().flatten()\n",
        "\n",
        "  predicted_labels.extend( predictions )\n",
        "  true_labels.extend( labels )\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24g_5Q0zrG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43158a2e-e433-42e1-a98c-969452345840"
      },
      "source": [
        "# Parameters:\n",
        "#BATCH = 16\n",
        "#epochs = 3\n",
        "#lr = 2e-5 # Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "#adam_epsilon = 1e-8\n",
        "#WARM_UP = 0.2\n",
        "# acc 0.72 f1 0.72\n",
        "from sklearn.metrics import classification_report \n",
        "print( classification_report(y_true=true_labels, y_pred=predicted_labels, zero_division=0) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.47      0.54        55\n",
            "           1       0.77      0.76      0.76       100\n",
            "           2       0.45      0.56      0.50        61\n",
            "\n",
            "    accuracy                           0.63       216\n",
            "   macro avg       0.61      0.60      0.60       216\n",
            "weighted avg       0.64      0.63      0.63       216\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC06qwV-xGAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89174a72-e51e-4a67-9865-8f656192a99d"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtlSH7RrxHBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98438ced-9e92-4b1b-d62e-6e73347692be"
      },
      "source": [
        "import os\n",
        "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
        "output_dir = \"/content/drive/My Drive/model_bert_finetuned_2\"\n",
        "\n",
        "# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
        "# If we have a distributed model, save only the encapsulated model\n",
        "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/model_bert_finetuned_2/vocab.txt',\n",
              " '/content/drive/My Drive/model_bert_finetuned_2/special_tokens_map.json',\n",
              " '/content/drive/My Drive/model_bert_finetuned_2/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2WUPnUGxLzq"
      },
      "source": [
        "# Step 2: Re-load the saved model and vocabulary\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD2zaD2E0f7Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU8i-NctwWAZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_LyZ8xRGNFD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}